<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>AI Chat Bot - OnlyourMiracle</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="OnlyourMiracle"><meta name="msapplication-TileImage" content="/download/DragonLogo2.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="OnlyourMiracle"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Learning record"><meta property="og:type" content="blog"><meta property="og:title" content="AI Chat Bot"><meta property="og:url" content="http://example.com/2024/03/13/AI%20Chat%20Bot/"><meta property="og:site_name" content="OnlyourMiracle"><meta property="og:description" content="Learning record"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://fancyerii.github.io/img/chatbot/seq2seq_batches.png"><meta property="og:image" content="https://fancyerii.github.io/img/chatbot/seq2seq_ts.png"><meta property="og:image" content="https://fancyerii.github.io/img/chatbot/RNN-bidirectional.png"><meta property="og:image" content="https://fancyerii.github.io/img/chatbot/scores.png"><meta property="og:image" content="https://fancyerii.github.io/img/chatbot/global_attn.png"><meta property="og:image" content="https://fancyerii.github.io/img/chatbot/grad_clip.png"><meta property="article:published_time" content="2024-03-13T13:29:55.798Z"><meta property="article:modified_time" content="2024-03-20T12:30:18.971Z"><meta property="article:author" content="OnlyourMiracle"><meta property="article:tag" content="AI"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://fancyerii.github.io/img/chatbot/seq2seq_batches.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com/2024/03/13/AI%20Chat%20Bot/"},"headline":"AI Chat Bot","image":["https://fancyerii.github.io/img/chatbot/seq2seq_batches.png","https://fancyerii.github.io/img/chatbot/seq2seq_ts.png","https://fancyerii.github.io/img/chatbot/RNN-bidirectional.png","https://fancyerii.github.io/img/chatbot/scores.png","https://fancyerii.github.io/img/chatbot/global_attn.png","https://fancyerii.github.io/img/chatbot/grad_clip.png"],"datePublished":"2024-03-13T13:29:55.798Z","dateModified":"2024-03-20T12:30:18.971Z","author":{"@type":"Person","name":"OnlyourMiracle"},"publisher":{"@type":"Organization","name":"OnlyourMiracle","logo":{"@type":"ImageObject","url":"http://example.com/download/DragonLogo2.png"}},"description":"Learning record"}</script><link rel="canonical" href="http://example.com/2024/03/13/AI%20Chat%20Bot/"><link rel="icon" href="/download/DragonLogo2.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }
          Array
              .from(document.querySelectorAll('.tab-content'))
              .forEach($tab => {
                  $tab.classList.add('is-hidden');
              });
          Array
              .from(document.querySelectorAll('.tabs li'))
              .forEach($tab => {
                  $tab.classList.remove('is-active');
              });
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/download/DragonLogo2.png" alt="OnlyourMiracle" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-03-13T13:29:55.798Z" title="3/13/2024, 9:29:55 PM">2024-03-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-03-20T12:30:18.971Z" title="3/20/2024, 8:30:18 PM">2024-03-20</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a></span><span class="level-item">2 hours read (About 15630 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">AI Chat Bot</h1><div class="content"><blockquote>
<p>This article records my process of creating an AI Chat Bot.</p>
</blockquote>
<span id="more"></span>

<h1 id="Chatbot-Tutorial"><a href="#Chatbot-Tutorial" class="headerlink" title="Chatbot Tutorial"></a>Chatbot Tutorial</h1><blockquote>
<p><a target="_blank" rel="noopener" href="http://fancyerii.github.io/2019/02/14/chatbot/">http://fancyerii.github.io/2019/02/14/chatbot/</a></p>
</blockquote>
<h1 id="使用PyTorch实现Chatbot"><a href="#使用PyTorch实现Chatbot" class="headerlink" title="使用PyTorch实现Chatbot"></a>使用PyTorch实现Chatbot</h1><p>本教程会介绍使用seq2seq模型实现一个chatbot，训练数据来自Cornell电影对话语料库。对话系统是目前的研究热点，它在客服、可穿戴设备和智能家居等场景有广泛应用。</p>
<p>传统的对话系统要么基于检索的方法——提前准备一个问答库，根据用户的输入寻找类似的问题和答案。这更像一个问答系统，它很难进行多轮的交互，而且答案是固定不变的。要么基于预先设置的对话流程，这主要用于slot-filling(Task-Oriented)的任务，比如查询机票需要用户提供日期，达到城市等信息。这种方法的缺点是比较死板，如果用户的意图在设计的流程之外，那么就无法处理，而且对话的流程也一般比较固定，要支持用户随意的话题内跳转和话题间切换比较困难。</p>
<p>因此目前学术界的研究热点是根据大量的对话数据，自动的End-to-End的使用Seq2Seq模型学习对话模型。它的好处是不需要人来设计这个对话流程，完全是数据驱动的方法。它的缺点是流程不受人(开发者)控制，在严肃的场景(比如客服)下使用会有比较大的风险，而且需要大量的对话数据，这在很多实际应用中是很难得到的。因此目前seq2seq模型的对话系统更多的是用于类似小冰的闲聊机器人上，最近也有不少论文研究把这种方法用于task-oriented的任务，但还不是太成熟，在业界还很少被使用。</p>
<h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p>本文使用的<a target="_blank" rel="noopener" href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html">Cornell电影对话语料库</a>就是偏向于闲聊的语料库。</p>
<p>本教程的主要内容参考了<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/chatbot_tutorial.html">PyTorch官方教程</a>。读者可以从<a target="_blank" rel="noopener" href="https://github.com/fancyerii/blog-codes">这里</a>获取完整代码。 下面是这个教程实现的对话效果示例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&gt; hello?</span><br><span class="line">Bot: hello .</span><br><span class="line">&gt; where am I?</span><br><span class="line">Bot: you re in a hospital .</span><br><span class="line">&gt; who are you?</span><br><span class="line">Bot: i m a lawyer .</span><br><span class="line">&gt; how are you doing?</span><br><span class="line">Bot: i m fine .</span><br><span class="line">&gt; are you my friend?</span><br><span class="line">Bot: no .</span><br><span class="line">&gt; you&#x27;re under arrest</span><br><span class="line">Bot: i m trying to help you !</span><br><span class="line">&gt; i&#x27;m just kidding</span><br><span class="line">Bot: i m sorry .</span><br><span class="line">&gt; where are you from?</span><br><span class="line">Bot: san francisco .</span><br><span class="line">&gt; it&#x27;s time for me to leave</span><br><span class="line">Bot: i know .</span><br><span class="line">&gt; goodbye</span><br><span class="line">Bot: goodbye .</span><br></pre></td></tr></table></figure>

<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>首先我们通过<a target="_blank" rel="noopener" href="http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip">下载链接</a>下载训练语料库，这是一个zip文件，把它下载后解压到项目目录的子目录data下。接下来我们导入需要用到的模块，这主要是PyTorch的模块：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">from __future__ import absolute_import</span><br><span class="line">from __future__ import division</span><br><span class="line">from __future__ import print_function</span><br><span class="line">from __future__ import unicode_literals</span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">from torch.jit import script, trace</span><br><span class="line">import torch.nn as nn</span><br><span class="line">from torch import optim</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import csv</span><br><span class="line">import random</span><br><span class="line">import re</span><br><span class="line">import os</span><br><span class="line">import unicodedata</span><br><span class="line">import codecs</span><br><span class="line">from io import open</span><br><span class="line">import itertools</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">USE_CUDA = torch.cuda.is_available()</span><br><span class="line">device = torch.device(&quot;cuda&quot; if USE_CUDA else &quot;cpu&quot;)</span><br></pre></td></tr></table></figure>

<h2 id="加载和预处理数据"><a href="#加载和预处理数据" class="headerlink" title="加载和预处理数据"></a>加载和预处理数据</h2><p>接下来我们需要对原始数据进行变换然后用合适的数据结构加载到内存里。</p>
<p><a target="_blank" rel="noopener" href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html">Cornell电影对话语料库</a>是电影人物的对话数据，它包括：</p>
<ul>
<li>10,292对电影人物(一部电影有多个人物，他们两两之间可能存在对话)的220,579个对话</li>
<li>617部电影的9,035个人物</li>
<li>总共304,713个utterance(utterance是对话中的语音片段，不一定是完整的句子)</li>
</ul>
<p>这个数据集是比较大并且多样的(diverse)，语言形式、时代和情感都有很多样。这样的数据可以使得我们的chatbot对于不同的输入更加鲁棒(robust)。</p>
<p>首先我们来看一下原始数据长什么样：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">corpus_name = &quot;cornell movie-dialogs corpus&quot;</span><br><span class="line">corpus = os.path.join(&quot;data&quot;, corpus_name)</span><br><span class="line"></span><br><span class="line">def printLines(file, n=10):</span><br><span class="line">    with open(file, &#x27;rb&#x27;) as datafile:</span><br><span class="line">        lines = datafile.readlines()</span><br><span class="line">    for line in lines[:n]:</span><br><span class="line">        print(line)</span><br><span class="line"></span><br><span class="line">printLines(os.path.join(corpus, &quot;movie_lines.txt&quot;))</span><br></pre></td></tr></table></figure>

<p>解压后的目录有很多文件，我们会用到的文件包括movie_lines.txt。上面的代码输出这个文件的前10行，结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">b&#x27;L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n&#x27;</span><br><span class="line">b&#x27;L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n&#x27;</span><br><span class="line">b&#x27;L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n&#x27;</span><br><span class="line">b&#x27;L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n&#x27;</span><br><span class="line">b&quot;L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let&#x27;s go.\n&quot;</span><br><span class="line">b&#x27;L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n&#x27;</span><br><span class="line">b&quot;L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you&#x27;re gonna need to learn how to lie.\n&quot;</span><br><span class="line">b&#x27;L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n&#x27;</span><br><span class="line">b&#x27;L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\&#x27;m kidding.  You know how sometimes you just become this &quot;persona&quot;?  And you don\&#x27;t know how to quit?\n&#x27;</span><br><span class="line">b&#x27;L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\n&#x27;</span><br></pre></td></tr></table></figure>

<p>注意：上面的move_lines.txt每行都是一个utterance，但是这个文件看不出哪些utterance是组成一段对话的，这需要 <em>movie_conversations.txt</em> 文件：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">data/cornell movie-dialogs corpus$ head movie_conversations.txt </span><br><span class="line">u0 +++$+++ u2 +++$+++ m0 +++$+++ [&#x27;L194&#x27;, &#x27;L195&#x27;, &#x27;L196&#x27;, &#x27;L197&#x27;]</span><br><span class="line">u0 +++$+++ u2 +++$+++ m0 +++$+++ [&#x27;L198&#x27;, &#x27;L199&#x27;]</span><br><span class="line">u0 +++$+++ u2 +++$+++ m0 +++$+++ [&#x27;L200&#x27;, &#x27;L201&#x27;, &#x27;L202&#x27;, &#x27;L203&#x27;]</span><br><span class="line">u0 +++$+++ u2 +++$+++ m0 +++$+++ [&#x27;L204&#x27;, &#x27;L205&#x27;, &#x27;L206&#x27;]</span><br><span class="line">u0 +++$+++ u2 +++$+++ m0 +++$+++ [&#x27;L207&#x27;, &#x27;L208&#x27;]</span><br><span class="line">u0 +++$+++ u2 +++$+++ m0 +++$+++ [&#x27;L271&#x27;, &#x27;L272&#x27;, &#x27;L273&#x27;, &#x27;L274&#x27;, &#x27;L275&#x27;]</span><br><span class="line">u0 +++$+++ u2 +++$+++ m0 +++$+++ [&#x27;L276&#x27;, &#x27;L277&#x27;]</span><br><span class="line">u0 +++$+++ u2 +++$+++ m0 +++$+++ [&#x27;L280&#x27;, &#x27;L281&#x27;]</span><br><span class="line">u0 +++$+++ u2 +++$+++ m0 +++$+++ [&#x27;L363&#x27;, &#x27;L364&#x27;]</span><br><span class="line">u0 +++$+++ u2 +++$+++ m0 +++$+++ [&#x27;L365&#x27;, &#x27;L366&#x27;]</span><br></pre></td></tr></table></figure>

<p>每一行用”+++$+++”分割成4列，第一列表示第一个人物的ID，第二列表示第二个人物的ID，第三列表示电影的ID，第四列表示这两个人物在这部电影中的一段对话，比如第一行的表示人物u0和u2在电影m0中的一段对话包含ID为L194、L195、L196和L197的4个utterance。注意：两个人物在一部电影中会有多段对话，中间可能穿插其他人之间的对话，而且即使中间没有其他人说话，这两个人物对话的内容从语义上也可能是属于不同的对话(话题)。所以我们看到第二行还是u0和u2在电影m0中的对话，它包含L198和L199两个utterance，L198是紧接着L197之后的，但是它们属于两个对话(话题)。</p>
<h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><p>为了使用方便，我们会把原始数据处理成一个新的文件，这个新文件的每一行都是用TAB分割问题(query)和答案(response)对。为了实现这个目的，我们首先定义一些用于parsing原始文件 <em>movie_lines.txt</em> 的辅助函数。</p>
<ul>
<li><code>loadLines</code> 把<em>movie_lines.txt</em> 文件切分成 (lineID, characterID, movieID, character, text)</li>
<li><code>loadConversations</code> 把上面的行group成一个个多轮的对话</li>
<li><code>extractSentencePairs</code> 从上面的每个对话中抽取句对</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"># 把每一行都parse成一个dict，key是lineID、characterID、movieID、character和text</span><br><span class="line"># 分别代表这一行的ID、人物ID、电影ID，人物名称和文本。</span><br><span class="line"># 最终输出一个dict，key是lineID，value是一个dict。</span><br><span class="line"># value这个dict的key是lineID、characterID、movieID、character和text</span><br><span class="line">def loadLines(fileName, fields):</span><br><span class="line">    lines = &#123;&#125;</span><br><span class="line">    with open(fileName, &#x27;r&#x27;, encoding=&#x27;iso-8859-1&#x27;) as f:</span><br><span class="line">        for line in f:</span><br><span class="line">            values = line.split(&quot; +++$+++ &quot;)</span><br><span class="line">            # 抽取fields</span><br><span class="line">            lineObj = &#123;&#125;</span><br><span class="line">            for i, field in enumerate(fields):</span><br><span class="line">                lineObj[field] = values[i]</span><br><span class="line">            lines[lineObj[&#x27;lineID&#x27;]] = lineObj</span><br><span class="line">    return lines</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 根据movie_conversations.txt文件和上输出的lines，把utterance组成对话。</span><br><span class="line"># 最终输出一个list，这个list的每一个元素都是一个dict，</span><br><span class="line"># key分别是character1ID、character2ID、movieID和utteranceIDs。</span><br><span class="line"># 分别表示这对话的第一个人物的ID，第二个的ID，电影的ID以及它包含的utteranceIDs</span><br><span class="line"># 最后根据lines，还给每一行的dict增加一个key为lines，其value是个list，</span><br><span class="line"># 包含所有utterance(上面得到的lines的value)</span><br><span class="line">def loadConversations(fileName, lines, fields):</span><br><span class="line">    conversations = []</span><br><span class="line">    with open(fileName, &#x27;r&#x27;, encoding=&#x27;iso-8859-1&#x27;) as f:</span><br><span class="line">        for line in f:</span><br><span class="line">            values = line.split(&quot; +++$+++ &quot;)</span><br><span class="line">            # 抽取fields</span><br><span class="line">            convObj = &#123;&#125;</span><br><span class="line">            for i, field in enumerate(fields):</span><br><span class="line">                convObj[field] = values[i]</span><br><span class="line">            # convObj[&quot;utteranceIDs&quot;]是一个字符串，形如[&#x27;L198&#x27;, &#x27;L199&#x27;]</span><br><span class="line">            # 我们用eval把这个字符串变成一个字符串的list。</span><br><span class="line">            lineIds = eval(convObj[&quot;utteranceIDs&quot;])</span><br><span class="line">            # 根据lineIds构造一个数组，根据lineId去lines里检索出存储utterance对象。</span><br><span class="line">            convObj[&quot;lines&quot;] = []</span><br><span class="line">            for lineId in lineIds:</span><br><span class="line">                convObj[&quot;lines&quot;].append(lines[lineId])</span><br><span class="line">            conversations.append(convObj)</span><br><span class="line">    return conversations</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 从对话中抽取句对 </span><br><span class="line"># 假设一段对话包含s1,s2,s3,s4这4个utterance</span><br><span class="line"># 那么会返回3个句对：s1-s2,s2-s3和s3-s4。</span><br><span class="line">def extractSentencePairs(conversations):</span><br><span class="line">    qa_pairs = []</span><br><span class="line">    for conversation in conversations:</span><br><span class="line">        # 遍历对话中的每一个句子，忽略最后一个句子，因为没有答案。</span><br><span class="line">        for i in range(len(conversation[&quot;lines&quot;]) - 1): </span><br><span class="line">            inputLine = conversation[&quot;lines&quot;][i][&quot;text&quot;].strip()</span><br><span class="line">            targetLine = conversation[&quot;lines&quot;][i+1][&quot;text&quot;].strip()</span><br><span class="line">            # 如果有空的句子就去掉 </span><br><span class="line">            if inputLine and targetLine:</span><br><span class="line">                qa_pairs.append([inputLine, targetLine])</span><br><span class="line">    return qa_pairs</span><br></pre></td></tr></table></figure>

<p>接下来我们利用上面的3个函数对原始数据进行处理，最终得到<em>formatted_movie_lines.txt</em>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"># 定义新的文件 </span><br><span class="line">datafile = os.path.join(corpus, &quot;formatted_movie_lines.txt&quot;)</span><br><span class="line"></span><br><span class="line">delimiter = &#x27;\t&#x27;</span><br><span class="line"># 对分隔符delimiter进行decode，这里对tab进行decode结果并没有变</span><br><span class="line">delimiter = str(codecs.decode(delimiter, &quot;unicode_escape&quot;))</span><br><span class="line"></span><br><span class="line"># 初始化dict lines，list conversations以及前面我们介绍过的field的id数组。</span><br><span class="line">lines = &#123;&#125;</span><br><span class="line">conversations = []</span><br><span class="line">MOVIE_LINES_FIELDS = [&quot;lineID&quot;, &quot;characterID&quot;, &quot;movieID&quot;, &quot;character&quot;, &quot;text&quot;]</span><br><span class="line">MOVIE_CONVERSATIONS_FIELDS = [&quot;character1ID&quot;, &quot;character2ID&quot;, &quot;movieID&quot;, &quot;utteranceIDs&quot;]</span><br><span class="line"></span><br><span class="line"># 首先使用loadLines函数处理movie_lines.txt </span><br><span class="line">print(&quot;\nProcessing corpus...&quot;)</span><br><span class="line">lines = loadLines(os.path.join(corpus, &quot;movie_lines.txt&quot;), MOVIE_LINES_FIELDS)</span><br><span class="line"># 接着使用loadConversations处理上一步的结果，得到conversations</span><br><span class="line">print(&quot;\nLoading conversations...&quot;)</span><br><span class="line">conversations = loadConversations(os.path.join(corpus, &quot;movie_conversations.txt&quot;),</span><br><span class="line">                                  lines, MOVIE_CONVERSATIONS_FIELDS)</span><br><span class="line"></span><br><span class="line"># 输出到一个新的csv文件</span><br><span class="line">print(&quot;\nWriting newly formatted file...&quot;)</span><br><span class="line">with open(datafile, &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;) as outputfile:</span><br><span class="line">    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator=&#x27;\n&#x27;)</span><br><span class="line">    # 使用extractSentencePairs从conversations里抽取句对。</span><br><span class="line">    for pair in extractSentencePairs(conversations):</span><br><span class="line">        writer.writerow(pair)</span><br><span class="line"></span><br><span class="line"># 输出一些行用于检查 </span><br><span class="line">print(&quot;\nSample lines from file:&quot;)</span><br><span class="line">printLines(datafile)</span><br></pre></td></tr></table></figure>

<p>上面的代码会生成一个新的文件formatted_movie_lines.txt，这文件每一行包含一对句对，用tab分割。下面是前十行：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">b&quot;Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\tWell, I thought we&#x27;d start with pronunciation, if that&#x27;s okay with you.\n&quot;</span><br><span class="line">b&quot;Well, I thought we&#x27;d start with pronunciation, if that&#x27;s okay with you.\tNot the hacking and gagging and spitting part.  Please.\n&quot;</span><br><span class="line">b&quot;Not the hacking and gagging and spitting part.  Please.\tOkay... then how &#x27;bout we try out some French cuisine.  Saturday?  Night?\n&quot;</span><br><span class="line">b&quot;You&#x27;re asking me out.  That&#x27;s so cute. What&#x27;s your name again?\tForget it.\n&quot;</span><br><span class="line">b&quot;No, no, it&#x27;s my fault -- we didn&#x27;t have a proper introduction ---\tCameron.\n&quot;</span><br><span class="line">b&quot;Cameron.\tThe thing is, Cameron -- I&#x27;m at the mercy of a particularly hideous breed of loser.  My sister.  I can&#x27;t date until she does.\n&quot;</span><br><span class="line">b&quot;The thing is, Cameron -- I&#x27;m at the mercy of a particularly hideous breed of loser.  My sister.  I can&#x27;t date until she does.\tSeems like she could get a date easy enough...\n&quot;</span><br><span class="line">b&#x27;Why?\tUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\n&#x27;</span><br><span class="line">b&quot;Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\tThat&#x27;s a shame.\n&quot;</span><br><span class="line">b&#x27;Gosh, if only we could find Kat a boyfriend...\tLet me see what I can do.\n&#x27;</span><br></pre></td></tr></table></figure>

<h3 id="创建词典"><a href="#创建词典" class="headerlink" title="创建词典"></a>创建词典</h3><p>接下来我们需要构建词典然后把问答句对加载到内存里。</p>
<p>我们的输入是一个句对，每个句子都是词的序列，但是机器学习只能处理数值，因此我们需要建立词到数字ID的映射。</p>
<p>为此，我们会定义一个<code>Voc</code>类，它会保存词到ID的映射，同时也保存反向的从ID到词的映射。除此之外，它还记录每个词出现的次数，以及总共出现的词的个数。这个类提供<code>addWord</code>方法来增加一个词， <code>addSentence</code>方法来增加句子，也提供方法<code>trim</code>来去除低频的词。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"># 预定义的token</span><br><span class="line">PAD_token = 0  # 表示padding </span><br><span class="line">SOS_token = 1  # 句子的开始 </span><br><span class="line">EOS_token = 2  # 句子的结束 </span><br><span class="line"></span><br><span class="line">class Voc:</span><br><span class="line">    def __init__(self, name):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.trimmed = False</span><br><span class="line">        self.word2index = &#123;&#125;</span><br><span class="line">        self.word2count = &#123;&#125;</span><br><span class="line">        self.index2word = &#123;PAD_token: &quot;PAD&quot;, SOS_token: &quot;SOS&quot;, EOS_token: &quot;EOS&quot;&#125;</span><br><span class="line">        self.num_words = 3  # 目前有SOS, EOS, PAD这3个token。</span><br><span class="line"></span><br><span class="line">    def addSentence(self, sentence):</span><br><span class="line">        for word in sentence.split(&#x27; &#x27;):</span><br><span class="line">            self.addWord(word)</span><br><span class="line"></span><br><span class="line">    def addWord(self, word):</span><br><span class="line">        if word not in self.word2index:</span><br><span class="line">            self.word2index[word] = self.num_words</span><br><span class="line">            self.word2count[word] = 1</span><br><span class="line">            self.index2word[self.num_words] = word</span><br><span class="line">            self.num_words += 1</span><br><span class="line">        else:</span><br><span class="line">            self.word2count[word] += 1</span><br><span class="line"></span><br><span class="line">    # 删除频次小于min_count的token </span><br><span class="line">    def trim(self, min_count):</span><br><span class="line">        if self.trimmed:</span><br><span class="line">            return</span><br><span class="line">        self.trimmed = True</span><br><span class="line"></span><br><span class="line">        keep_words = []</span><br><span class="line"></span><br><span class="line">        for k, v in self.word2count.items():</span><br><span class="line">            if v &gt;= min_count:</span><br><span class="line">                keep_words.append(k)</span><br><span class="line"></span><br><span class="line">        print(&#x27;keep_words &#123;&#125; / &#123;&#125; = &#123;:.4f&#125;&#x27;.format(</span><br><span class="line">            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)</span><br><span class="line">        ))</span><br><span class="line"></span><br><span class="line">        # 重新构造词典 </span><br><span class="line">        self.word2index = &#123;&#125;</span><br><span class="line">        self.word2count = &#123;&#125;</span><br><span class="line">        self.index2word = &#123;PAD_token: &quot;PAD&quot;, SOS_token: &quot;SOS&quot;, EOS_token: &quot;EOS&quot;&#125;</span><br><span class="line">        self.num_words = 3 # Count default tokens</span><br><span class="line">        </span><br><span class="line">        # 重新构造后词频就没有意义了(都是1)</span><br><span class="line">        for word in keep_words:</span><br><span class="line">            self.addWord(word)</span><br></pre></td></tr></table></figure>

<p>有了上面的Voc类我们就可以通过问答句对来构建词典了。但是在构建之前我们需要进行一些预处理。</p>
<p>首先我们需要使用函数<code>unicodeToAscii</code>来把unicode字符变成ascii，比如把à变成a。注意，这里的代码只是用于处理西方文字，如果是中文，这个函数直接会丢弃掉。接下来把所有字母变成小写同时丢弃掉字母和常见标点(.!?)之外的所有字符。最后为了训练收敛，我们会用函数<code>filterPairs</code>去掉长度超过<code>MAX_LENGTH</code>的句子(句对)。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">MAX_LENGTH = 10  # 句子最大长度是10个词(包括EOS等特殊词)</span><br><span class="line"></span><br><span class="line"># 把Unicode字符串变成ASCII</span><br><span class="line"># 参考https://stackoverflow.com/a/518232/2809427</span><br><span class="line">def unicodeToAscii(s):</span><br><span class="line">    return &#x27;&#x27;.join(</span><br><span class="line">        c for c in unicodedata.normalize(&#x27;NFD&#x27;, s)</span><br><span class="line">        if unicodedata.category(c) != &#x27;Mn&#x27;</span><br><span class="line">    )</span><br><span class="line"> </span><br><span class="line">def normalizeString(s):</span><br><span class="line">    # 变成小写、去掉前后空格，然后unicode变成ascii</span><br><span class="line">    s = unicodeToAscii(s.lower().strip())</span><br><span class="line">    # 在标点前增加空格，这样把标点当成一个词</span><br><span class="line">    s = re.sub(r&quot;([.!?])&quot;, r&quot; \1&quot;, s)</span><br><span class="line">    # 字母和标点之外的字符都变成空格</span><br><span class="line">    s = re.sub(r&quot;[^a-zA-Z.!?]+&quot;, r&quot; &quot;, s)</span><br><span class="line">    # 因为把不用的字符都变成空格，所以可能存在多个连续空格</span><br><span class="line">    # 下面的正则替换把多个空格变成一个空格，最后去掉前后空格</span><br><span class="line">    s = re.sub(r&quot;\s+&quot;, r&quot; &quot;, s).strip()</span><br><span class="line">    return s</span><br><span class="line"></span><br><span class="line"># 读取问答句对并且返回Voc词典对象 </span><br><span class="line">def readVocs(datafile, corpus_name):</span><br><span class="line">    print(&quot;Reading lines...&quot;)</span><br><span class="line">    # 文件每行读取到list lines中。 </span><br><span class="line">    lines = open(datafile, encoding=&#x27;utf-8&#x27;).\</span><br><span class="line">        read().strip().split(&#x27;\n&#x27;)</span><br><span class="line">    # 每行用tab切分成问答两个句子，然后调用normalizeString函数进行处理。</span><br><span class="line">    pairs = [[normalizeString(s) for s in l.split(&#x27;\t&#x27;)] for l in lines]</span><br><span class="line">    voc = Voc(corpus_name)</span><br><span class="line">    return voc, pairs</span><br><span class="line"></span><br><span class="line">def filterPair(p): </span><br><span class="line">    return len(p[0].split(&#x27; &#x27;)) &lt; MAX_LENGTH and len(p[1].split(&#x27; &#x27;)) &lt; MAX_LENGTH</span><br><span class="line"></span><br><span class="line"># 过滤太长的句对 </span><br><span class="line">def filterPairs(pairs):</span><br><span class="line">    return [pair for pair in pairs if filterPair(pair)]</span><br><span class="line"></span><br><span class="line"># 使用上面的函数进行处理，返回Voc对象和句对的list </span><br><span class="line">def loadPrepareData(corpus, corpus_name, datafile):</span><br><span class="line">    print(&quot;Start preparing training data ...&quot;)</span><br><span class="line">    voc, pairs = readVocs(datafile, corpus_name)</span><br><span class="line">    print(&quot;Read &#123;!s&#125; sentence pairs&quot;.format(len(pairs)))</span><br><span class="line">    pairs = filterPairs(pairs)</span><br><span class="line">    print(&quot;Trimmed to &#123;!s&#125; sentence pairs&quot;.format(len(pairs)))</span><br><span class="line">    print(&quot;Counting words...&quot;)</span><br><span class="line">    for pair in pairs:</span><br><span class="line">        voc.addSentence(pair[0])</span><br><span class="line">        voc.addSentence(pair[1])</span><br><span class="line">    print(&quot;Counted words:&quot;, voc.num_words)</span><br><span class="line">    return voc, pairs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Load/Assemble voc and pairs</span><br><span class="line"># save_dir = os.path.join(&quot;data&quot;, &quot;save&quot;)</span><br><span class="line">voc, pairs = loadPrepareData(corpus, corpus_name, datafile)</span><br><span class="line"># 输出一些句对</span><br><span class="line">print(&quot;\npairs:&quot;)</span><br><span class="line">for pair in pairs[:10]:</span><br><span class="line">    print(pair)</span><br></pre></td></tr></table></figure>

<p>上面的代码的输出为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Start preparing training data ...</span><br><span class="line">Reading lines...</span><br><span class="line">Read 221282 sentence pairs</span><br><span class="line">Trimmed to 64271 sentence pairs</span><br><span class="line">Counting words...</span><br><span class="line">Counted words: 18008</span><br></pre></td></tr></table></figure>

<p>我们可以看到，原来共有221282个句对，经过处理后我们只保留了64271个句对。</p>
<p>另外为了收敛更快，我们可以去除掉一些低频词。这可以分为两步：</p>
<ol>
<li>使用<code>voc.trim</code>函数去掉频次低于<code>MIN_COUNT</code> 的词。</li>
<li>去掉包含低频词的句子(只保留这样的句子——每一个词都是高频的，也就是在voc中出现的)</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">MIN_COUNT = 3    # 阈值为3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def trimRareWords(voc, pairs, MIN_COUNT):</span><br><span class="line">    # 去掉voc中频次小于3的词 </span><br><span class="line">    voc.trim(MIN_COUNT)</span><br><span class="line">    # 保留的句对 </span><br><span class="line">    keep_pairs = []</span><br><span class="line">    for pair in pairs:</span><br><span class="line">        input_sentence = pair[0]</span><br><span class="line">        output_sentence = pair[1]</span><br><span class="line">        keep_input = True</span><br><span class="line">        keep_output = True</span><br><span class="line">        # 检查问题</span><br><span class="line">        for word in input_sentence.split(&#x27; &#x27;):</span><br><span class="line">            if word not in voc.word2index:</span><br><span class="line">                keep_input = False</span><br><span class="line">                break</span><br><span class="line">        # 检查答案</span><br><span class="line">        for word in output_sentence.split(&#x27; &#x27;):</span><br><span class="line">            if word not in voc.word2index:</span><br><span class="line">                keep_output = False</span><br><span class="line">                break</span><br><span class="line"></span><br><span class="line">        # 如果问题和答案都只包含高频词，我们才保留这个句对</span><br><span class="line">        if keep_input and keep_output:</span><br><span class="line">            keep_pairs.append(pair)</span><br><span class="line"></span><br><span class="line">    print(&quot;Trimmed from &#123;&#125; pairs to &#123;&#125;, &#123;:.4f&#125; of total&quot;.format(len(pairs), </span><br><span class="line">		len(keep_pairs), len(keep_pairs) / len(pairs)))</span><br><span class="line">    return keep_pairs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 实际进行处理</span><br><span class="line">pairs = trimRareWords(voc, pairs, MIN_COUNT)</span><br></pre></td></tr></table></figure>

<p>代码的输出为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">keep_words 7823 / 18005 = 0.4345</span><br><span class="line">Trimmed from 64271 pairs to 53165, 0.8272 of total</span><br></pre></td></tr></table></figure>

<p>18005个词之中，频次大于等于3的只有43%，去掉低频的57%的词之后，保留的句子为53165，占比为82%。</p>
<h3 id="为模型准备数据"><a href="#为模型准备数据" class="headerlink" title="为模型准备数据"></a>为模型准备数据</h3><p>前面我们构建了词典，并且对训练数据进行预处理并且滤掉一些句对，但是模型最终用到的是Tensor。最简单的办法是一次处理一个句对，那么上面得到的句对直接就可以使用。但是为了加快训练速度，尤其是重复利用GPU的并行能力，我们需要一次处理一个batch的数据。</p>
<p>对于某些问题，比如图像来说，输入可能是固定大小的(或者通过预处理缩放成固定大小），但是对于文本来说，我们很难把一个二十个词的句子”缩放”成十个词同时还保持语义不变。但是为了充分利用GPU等计算自由，我们又必须变成固定大小的Tensor，因此我们通常会使用Padding的技巧，把短的句子补充上零使得输入大小是(batch, max_length)，这样通过一次就能实现一个batch数据的forward或者backward计算。当然padding的部分的结果是没有意义的，比如某个句子实际长度是5，而max_length是10，那么最终forward的输出应该是第5个时刻的输出，后面5个时刻计算是无用功。方向计算梯度的时候也是类似的，我们需要从第5个时刻开始反向计算梯度。为了提高效率，我们通常把长度接近的训练数据放到一个batch里面，这样无用的计算是最少的。因此我们通常把全部训练数据根据长度划分成一些组，比如长度小于4的一组，长度4到8的一组，长度8到12的一组，…。然后每次随机的选择一个组，再随机的从一组里选择batch个数据。不过本教程并没有这么做，而是每次随机的从所有pair里随机选择batch个数据。</p>
<p>原始的输入通常是batch个list，表示batch个句子，因此自然的表示方法为(batch, max_length)，这种表示方法第一维是batch，每移动一个下标得到的是一个样本的max_length个词(包括padding)。因为RNN的依赖关系，我们在计算t+1时刻必须知道t时刻的结果，因此我们无法用多个核同时计算一个样本的forward。但是不同样本之间是没有依赖关系的，因此我们可以在根据t时刻batch样本的当前状态计算batch个样本的输出和新状态，然后再计算t+2时刻，…。为了便于GPU一次取出t时刻的batch个数据，我们通常把输入从(batch, max_length)变成(max_length, batch)，这样使得t时刻的batch个数据在内存(显存)中是连续的，从而读取效率更高。这个过程如下图所示，原始输入的大小是(batch&#x3D;6, max_length&#x3D;4)，转置之后变成(4,6)。这样某个时刻的6个样本数据在内存中是连续的。</p>
<p><img src="https://fancyerii.github.io/img/chatbot/seq2seq_batches.png" alt="img"></p>
<p>因此我们会用一些工具函数来实现上述处理。</p>
<p><code>inputVar</code>函数把batch个句子padding后变成一个LongTensor，大小是(max_length, batch)，同时会返回一个大小是batch的list lengths，说明每个句子的实际长度，这个参数后面会传给PyTorch，从而在forward和backward计算的时候使用实际的长度。</p>
<p><code>outputVar</code>函数和<code>inputVar</code>类似，但是它输出的第二个参数不是lengths，而是一个大小为(max_length, batch)的mask矩阵(tensor)，某位是0表示这个位置是padding，1表示不是padding，这样做的目的是后面计算方便。当然这两种表示是等价的，只不过lengths表示更加紧凑，但是计算起来不同方便，而mask矩阵和outputVar直接相乘就可以把padding的位置给mask(变成0)掉，这在计算loss时会非常方便。</p>
<p><code>batch2TrainData</code> 则利用上面的两个函数把一个batch的句对处理成合适的输入和输出Tensor。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"># 把句子的词变成ID</span><br><span class="line">def indexesFromSentence(voc, sentence):</span><br><span class="line">    return [voc.word2index[word] for word in sentence.split(&#x27; &#x27;)] + [EOS_token]</span><br><span class="line"></span><br><span class="line"># l是多个长度不同句子(list)，使用zip_longest padding成定长，长度为最长句子的长度。</span><br><span class="line">def zeroPadding(l, fillvalue=PAD_token):</span><br><span class="line">    return list(itertools.zip_longest(*l, fillvalue=fillvalue))</span><br><span class="line"></span><br><span class="line"># l是二维的padding后的list</span><br><span class="line"># 返回m和l的大小一样，如果某个位置是padding，那么值为0，否则为1</span><br><span class="line">def binaryMatrix(l, value=PAD_token):</span><br><span class="line">    m = []</span><br><span class="line">    for i, seq in enumerate(l):</span><br><span class="line">        m.append([])</span><br><span class="line">        for token in seq:</span><br><span class="line">            if token == PAD_token:</span><br><span class="line">                m[i].append(0)</span><br><span class="line">            else:</span><br><span class="line">                m[i].append(1)</span><br><span class="line">    return m</span><br><span class="line"></span><br><span class="line"># 把输入句子变成ID，然后再padding，同时返回lengths这个list，标识实际长度。</span><br><span class="line"># 返回的padVar是一个LongTensor，shape是(batch, max_length)，</span><br><span class="line"># lengths是一个list，长度为(batch,)，表示每个句子的实际长度。</span><br><span class="line">def inputVar(l, voc):</span><br><span class="line">    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]</span><br><span class="line">    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])</span><br><span class="line">    padList = zeroPadding(indexes_batch)</span><br><span class="line">    padVar = torch.LongTensor(padList)</span><br><span class="line">    return padVar, lengths</span><br><span class="line"></span><br><span class="line"># 对输出句子进行padding，然后用binaryMatrix得到每个位置是padding(0)还是非padding，</span><br><span class="line"># 同时返回最大最长句子的长度(也就是padding后的长度)</span><br><span class="line"># 返回值padVar是LongTensor，shape是(batch, max_target_length)</span><br><span class="line"># mask是ByteTensor，shape也是(batch, max_target_length)</span><br><span class="line">def outputVar(l, voc):</span><br><span class="line">    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]</span><br><span class="line">    max_target_len = max([len(indexes) for indexes in indexes_batch])</span><br><span class="line">    padList = zeroPadding(indexes_batch)</span><br><span class="line">    mask = binaryMatrix(padList)</span><br><span class="line">    mask = torch.ByteTensor(mask)</span><br><span class="line">    padVar = torch.LongTensor(padList)</span><br><span class="line">    return padVar, mask, max_target_len</span><br><span class="line"></span><br><span class="line"># 处理一个batch的pair句对 </span><br><span class="line">def batch2TrainData(voc, pair_batch):</span><br><span class="line">    # 按照句子的长度(词数)排序</span><br><span class="line">    pair_batch.sort(key=lambda x: len(x[0].split(&quot; &quot;)), reverse=True)</span><br><span class="line">    input_batch, output_batch = [], []</span><br><span class="line">    for pair in pair_batch:</span><br><span class="line">        input_batch.append(pair[0])</span><br><span class="line">        output_batch.append(pair[1])</span><br><span class="line">    inp, lengths = inputVar(input_batch, voc)</span><br><span class="line">    output, mask, max_target_len = outputVar(output_batch, voc)</span><br><span class="line">    return inp, lengths, output, mask, max_target_len</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">small_batch_size = 5</span><br><span class="line">batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])</span><br><span class="line">input_variable, lengths, target_variable, mask, max_target_len = batches</span><br><span class="line"></span><br><span class="line">print(&quot;input_variable:&quot;, input_variable)</span><br><span class="line">print(&quot;lengths:&quot;, lengths)</span><br><span class="line">print(&quot;target_variable:&quot;, target_variable)</span><br><span class="line">print(&quot;mask:&quot;, mask)</span><br><span class="line">print(&quot;max_target_len:&quot;, max_target_len)</span><br></pre></td></tr></table></figure>

<p>示例的输出为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">input_variable: tensor(</span><br><span class="line">       [[   92,   101,    76,    50,    34],</span><br><span class="line">        [    7,   250,    37,     6,     4],</span><br><span class="line">        [  123,   279,   628,     2,     2],</span><br><span class="line">        [   40,    75,     4,     0,     0],</span><br><span class="line">        [  359,    53,  7216,     0,     0],</span><br><span class="line">        [ 2763,   217,     4,     0,     0],</span><br><span class="line">        [  637,     4,     2,     0,     0],</span><br><span class="line">        [    6,     2,     0,     0,     0],</span><br><span class="line">        [    2,     0,     0,     0,     0]])</span><br><span class="line">lengths: tensor([ 9,  8,  7,  3,  3])</span><br><span class="line">target_variable: tensor(</span><br><span class="line">       [[   25,    34,   404,     7,    25],</span><br><span class="line">        [  283,     4,    76,    24,  1464],</span><br><span class="line">        [   25,     2,    37,     4,    70],</span><br><span class="line">        [   72,     0,  7217,     2,  1465],</span><br><span class="line">        [  829,     0,     4,     0,     6],</span><br><span class="line">        [  234,     0,     2,     0,     2],</span><br><span class="line">        [    4,     0,     0,     0,     0],</span><br><span class="line">        [    2,     0,     0,     0,     0]])</span><br><span class="line">mask: tensor(</span><br><span class="line">       [[ 1,  1,  1,  1,  1],</span><br><span class="line">        [ 1,  1,  1,  1,  1],</span><br><span class="line">        [ 1,  1,  1,  1,  1],</span><br><span class="line">        [ 1,  0,  1,  1,  1],</span><br><span class="line">        [ 1,  0,  1,  0,  1],</span><br><span class="line">        [ 1,  0,  1,  0,  1],</span><br><span class="line">        [ 1,  0,  0,  0,  0],</span><br><span class="line">        [ 1,  0,  0,  0,  0]], dtype=torch.uint8)</span><br><span class="line">max_target_len: 8</span><br></pre></td></tr></table></figure>

<p>我们可以看到input_variable的每一列表示一个样本，而每一行表示batch(5)个样本在这个时刻的值。而lengths表示真实的长度。类似的target_variable也是每一列表示一个样本，而mask的shape和target_variable一样，如果某个位置是0，则表示padding。</p>
<h2 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h2><h3 id="Seq2Seq-模型"><a href="#Seq2Seq-模型" class="headerlink" title="Seq2Seq 模型"></a>Seq2Seq 模型</h3><p>我们这个chatbot的核心是一个sequence-to-sequence(seq2seq)模型。 seq2seq模型的输入是一个变长的序列，而输出也是一个变长的序列。而且这两个序列的长度并不相同。一般我们使用RNN来处理变长的序列，Sutskever等人的<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1409.3215">论文</a>发现通过使用两个RNN可以解决这类问题。这类问题的输入和输出都是变长的而且长度不一样，包括问答系统、机器翻译、自动摘要等等都可以使用seq2seq模型来解决。其中一个RNN叫做Encoder，它把变长的输入序列编码成一个固定长度的context向量，我们一般可以认为这个向量包含了输入句子的语义。而第二个RNN叫做Decoder，初始隐状态是Encoder的输出context向量，输入是(表示句子开始的特殊Token)，然后用RNN计算第一个时刻的输出，接着用第一个时刻的输出和隐状态计算第二个时刻的输出和新的隐状态，…，直到某个时刻输出特殊的(表示句子结束的特殊Token)或者长度超过一个阈值。Seq2Seq模型如下图所示。</p>
<p><img src="https://fancyerii.github.io/img/chatbot/seq2seq_ts.png" alt="Seq2Seq模型"></p>
<h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p>Encoder是个RNN，它会遍历输入的每一个Token(词)，每个时刻的输入是上一个时刻的隐状态和输入，然后会有一个输出和新的隐状态。这个新的隐状态会作为下一个时刻的输入隐状态。每个时刻都有一个输出，对于seq2seq模型来说，我们通常只保留最后一个时刻的隐状态，认为它编码了整个句子的语义，但是后面我们会用到Attention机制，它还会用到Encoder每个时刻的输出。Encoder处理结束后会把最后一个时刻的隐状态作为Decoder的初始隐状态。</p>
<p>实际我们通常使用多层的Gated Recurrent Unit(GRU)或者LSTM来作为Encoder，这里使用GRU，读者可以参考Cho等人2014年的[论文]。</p>
<p>此外我们会使用双向的RNN，如下图所示。</p>
<p><img src="https://fancyerii.github.io/img/chatbot/RNN-bidirectional.png" alt="img"></p>
<p>注意在接入RNN之前会有一个<code>embedding</code>层，用来把每一个词(ID或者one-hot向量)映射成一个连续的稠密的向量，我们可以认为这个向量编码了一个词的语义。在我们的模型里，我们把它的大小定义成和RNN的隐状态大小一样(但是并不是一定要一样)。有了Embedding之后，模型会把相似的词编码成相似的向量(距离比较近)。</p>
<p>最后，为了把padding的batch数据传给RNN，我们需要使用下面的两个函数来进行pack和unpack，后面我们会详细介绍它们。这两个函数是：</p>
<ul>
<li><code>torch.nn.utils.rnn.pack_padded_sequence</code></li>
<li><code>torch.nn.utils.rnn.pad_packed_sequence</code></li>
</ul>
<p><strong>计算图:</strong></p>
<ol>
<li>把词的ID通过Embedding层变成向量。 2) 把padding后的数据进行pack。 3) 传入GRU进行Forward计算。 4) Unpack计算结果 5) 把双向GRU的结果向量加起来。 6) 返回(所有时刻的)输出和最后时刻的隐状态。</li>
</ol>
<p><strong>输入:</strong></p>
<ul>
<li><code>input_seq</code>: 一个batch的输入句子，shape是(max_length, batch_size)</li>
<li><code>input_lengths</code>: 一个长度为batch的list，表示句子的实际长度。</li>
<li><code>hidden</code>: 初始化隐状态(通常是零)，shape是(n_layers x num_directions, batch_size, hidden_size)</li>
</ul>
<p><strong>输出:</strong></p>
<ul>
<li><code>outputs</code>: 最后一层GRU的输出向量(双向的向量加在了一起)，shape(max_length, batch_size, hidden_size)</li>
<li><code>hidden</code>: 最后一个时刻的隐状态，shape是(n_layers x num_directions, batch_size, hidden_size)</li>
</ul>
<p>EncoderRNN代码如下，请读者详细阅读注释。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">class EncoderRNN(nn.Module):</span><br><span class="line">    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):</span><br><span class="line">        super(EncoderRNN, self).__init__()</span><br><span class="line">        self.n_layers = n_layers</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.embedding = embedding</span><br><span class="line"></span><br><span class="line">        # 初始化GRU，这里输入和hidden大小都是hidden_size，这里假设embedding层的输出大小是hidden_size</span><br><span class="line">        # 如果只有一层，那么不进行Dropout，否则使用传入的参数dropout进行GRU的Dropout。</span><br><span class="line">        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,</span><br><span class="line">                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)</span><br><span class="line"></span><br><span class="line">    def forward(self, input_seq, input_lengths, hidden=None):</span><br><span class="line">        # 输入是(max_length, batch)，Embedding之后变成(max_length, batch, hidden_size)</span><br><span class="line">        embedded = self.embedding(input_seq)</span><br><span class="line">        # Pack padded batch of sequences for RNN module</span><br><span class="line">        # 因为RNN(GRU)要知道实际长度，所以PyTorch提供了函数pack_padded_sequence把输入向量和长度</span><br><span class="line">        # pack到一个对象PackedSequence里，这样便于使用。</span><br><span class="line">        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)</span><br><span class="line">        # 通过GRU进行forward计算，需要传入输入和隐变量</span><br><span class="line">        # 如果传入的输入是一个Tensor (max_length, batch, hidden_size)</span><br><span class="line">        # 那么输出outputs是(max_length, batch, hidden_size*num_directions)。</span><br><span class="line">        # 第三维是hidden_size和num_directions的混合，它们实际排列顺序是num_directions在前面，</span><br><span class="line">        # 因此我们可以使用outputs.view(seq_len, batch, num_directions, hidden_size)得到4维的向量。</span><br><span class="line">        # 其中第三维是方向，第四位是隐状态。</span><br><span class="line">        </span><br><span class="line">        # 而如果输入是PackedSequence对象，那么输出outputs也是一个PackedSequence对象，我们需要用</span><br><span class="line">        # 函数pad_packed_sequence把它变成shape为(max_length, batch, hidden*num_directions)的向量以及</span><br><span class="line">        # 一个list，表示输出的长度，当然这个list和输入的input_lengths完全一样，因此通常我们不需要它。</span><br><span class="line">        outputs, hidden = self.gru(packed, hidden)</span><br><span class="line">        # 参考前面的注释，我们得到outputs为(max_length, batch, hidden*num_directions)</span><br><span class="line">        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)</span><br><span class="line">        # 我们需要把输出的num_directions双向的向量加起来</span><br><span class="line">        # 因为outputs的第三维是先放前向的hidden_size个结果，然后再放后向的hidden_size个结果</span><br><span class="line">        # 所以outputs[:, :, :self.hidden_size]得到前向的结果</span><br><span class="line">        # outputs[:, :, self.hidden_size:]是后向的结果</span><br><span class="line">        # 注意，如果bidirectional是False，则outputs第三维的大小就是hidden_size，</span><br><span class="line">        # 这时outputs[:, : ,self.hidden_size:]是不存在的，因此也不会加上去。</span><br><span class="line">        # 对Python slicing不熟的读者可以看看下面的例子：</span><br><span class="line">        </span><br><span class="line">        # &gt;&gt;&gt; a=[1,2,3]</span><br><span class="line">        # &gt;&gt;&gt; a[:3]</span><br><span class="line">        # [1, 2, 3]</span><br><span class="line">        # &gt;&gt;&gt; a[3:]</span><br><span class="line">        # []</span><br><span class="line">        # &gt;&gt;&gt; a[:3]+a[3:]</span><br><span class="line">        # [1, 2, 3]</span><br><span class="line">        </span><br><span class="line">        # 这样就不用写下面的代码了：</span><br><span class="line">        # if bidirectional:</span><br><span class="line">        #     outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]</span><br><span class="line">        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]</span><br><span class="line">        # 返回最终的输出和最后时刻的隐状态。 </span><br><span class="line">        return outputs, hidden</span><br></pre></td></tr></table></figure>

<h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>Decoder也是一个RNN，它每个时刻输出一个词。每个时刻的输入是上一个时刻的隐状态和上一个时刻的输出。一开始的隐状态是Encoder最后时刻的隐状态，输入是特殊的。然后使用RNN计算新的隐状态和输出第一个词，接着用新的隐状态和第一个词计算第二个词，…，直到遇到，结束输出。普通的RNN Decoder的问题是它只依赖与Encoder最后一个时刻的隐状态，虽然理论上这个隐状态(context向量)可以编码输入句子的语义，但是实际会比较困难。因此当输入句子很长的时候，效果会很长。</p>
<p>为了解决这个问题，Bahdanau等人在<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1409.0473">论文</a>里提出了注意力机制(attention mechanism)，在Decoder进行t时刻计算的时候，除了t-1时刻的隐状态，当前时刻的输入，注意力机制还可以参考Encoder所有时刻的输入。拿机器翻译来说，我们在翻译以句子的第t个词的时候会把注意力机制在某个词上。当然常见的注意力是一种soft的注意力，假设输入有5个词，注意力可能是一个概率，比如(0.6,0.1,0.1,0.1,0.1)，表示当前最关注的是输入的第一个词。同时我们之前也计算出每个时刻的输出向量，假设5个时刻分别是𝑦1,…,𝑦5�1,…,�5，那么我们可以用attention概率加权得到当前时刻的context向量0.6𝑦1+0.1𝑦2+…+0.1𝑦50.6�1+0.1�2+…+0.1�5。</p>
<p>注意力有很多方法计算，我们这里介绍Luong等人在<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1508.04025">论文</a>提出的方法。它是用当前时刻的GRU计算出的新的隐状态来计算注意力得分，首先它用一个score函数计算这个隐状态和Encoder的输出的相似度得分，得分越大，说明越应该注意这个词。然后再用softmax函数把score变成概率。那机器翻译为例，在t时刻，ℎ𝑡ℎ�表示t时刻的GRU输出的新的隐状态，我们可以认为ℎ𝑡ℎ�表示当前需要翻译的语义。通过计算ℎ𝑡ℎ�与𝑦1,…,𝑦𝑛�1,…,��的得分，如果ℎ𝑡ℎ�与𝑦1�1的得分很高，那么我们可以认为当前主要翻译词𝑥1�1的语义。有很多中score函数的计算方法，如下图所示：</p>
<p><img src="https://fancyerii.github.io/img/chatbot/scores.png" alt="img"></p>
<p>上式中ℎ𝑡ℎ�表示t时刻的隐状态，比如第一种计算score的方法，直接计算ℎ𝑡ℎ�与ℎ𝑠ℎ�的内积，内积越大，说明这两个向量越相似，因此注意力也更多的放到这个词上。第二种方法也类似，只是引入了一个可以学习的矩阵，我们可以认为它先对ℎ𝑡ℎ�做一个线性变换，然后在与ℎ𝑠ℎ�计算内积。而第三种方法把它们拼接起来然后用一个全连接网络来计算score。</p>
<p>注意，我们前面介绍的是分别计算ℎ𝑡ℎ�和𝑦1�1的内积、ℎ𝑡ℎ�和𝑦2�2的内积，…。但是为了效率，可以一次计算ℎ𝑡ℎ�与ℎ𝑠&#x3D;[𝑦1,𝑦2,…,𝑦𝑛]ℎ�&#x3D;[�1,�2,…,��]的乘积。 计算过程如下图所示。</p>
<p><img src="https://fancyerii.github.io/img/chatbot/global_attn.png" alt="img"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"># Luong 注意力layer</span><br><span class="line">class Attn(torch.nn.Module):</span><br><span class="line">    def __init__(self, method, hidden_size):</span><br><span class="line">        super(Attn, self).__init__()</span><br><span class="line">        self.method = method</span><br><span class="line">        if self.method not in [&#x27;dot&#x27;, &#x27;general&#x27;, &#x27;concat&#x27;]:</span><br><span class="line">            raise ValueError(self.method, &quot;is not an appropriate attention method.&quot;)</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        if self.method == &#x27;general&#x27;:</span><br><span class="line">            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)</span><br><span class="line">        elif self.method == &#x27;concat&#x27;:</span><br><span class="line">            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)</span><br><span class="line">            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))</span><br><span class="line"></span><br><span class="line">    def dot_score(self, hidden, encoder_output):</span><br><span class="line">        # 输入hidden的shape是(1, batch=64, hidden_size=500)</span><br><span class="line">        # encoder_outputs的shape是(input_lengths=10, batch=64, hidden_size=500)</span><br><span class="line">        # hidden * encoder_output得到的shape是(10, 64, 500)，然后对第3维求和就可以计算出score。</span><br><span class="line">        return torch.sum(hidden * encoder_output, dim=2)</span><br><span class="line"></span><br><span class="line">    def general_score(self, hidden, encoder_output):</span><br><span class="line">        energy = self.attn(encoder_output)</span><br><span class="line">        return torch.sum(hidden * energy, dim=2)</span><br><span class="line"></span><br><span class="line">    def concat_score(self, hidden, encoder_output):</span><br><span class="line">        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), </span><br><span class="line">				      encoder_output), 2)).tanh()</span><br><span class="line">        return torch.sum(self.v * energy, dim=2)</span><br><span class="line">    </span><br><span class="line">    # 输入是上一个时刻的隐状态hidden和所有时刻的Encoder的输出encoder_outputs</span><br><span class="line">    # 输出是注意力的概率，也就是长度为input_lengths的向量，它的和加起来是1。</span><br><span class="line">    def forward(self, hidden, encoder_outputs):</span><br><span class="line">        # 计算注意力的score，输入hidden的shape是(1, batch=64, hidden_size=500)，</span><br><span class="line">        # 表示t时刻batch数据的隐状态</span><br><span class="line">        # encoder_outputs的shape是(input_lengths=10, batch=64, hidden_size=500) </span><br><span class="line">        if self.method == &#x27;general&#x27;:</span><br><span class="line">            attn_energies = self.general_score(hidden, encoder_outputs)</span><br><span class="line">        elif self.method == &#x27;concat&#x27;:</span><br><span class="line">            attn_energies = self.concat_score(hidden, encoder_outputs)</span><br><span class="line">        elif self.method == &#x27;dot&#x27;:</span><br><span class="line">            # 计算内积，参考dot_score函数</span><br><span class="line">            attn_energies = self.dot_score(hidden, encoder_outputs)</span><br><span class="line"></span><br><span class="line">        # Transpose max_length and batch_size dimensions</span><br><span class="line">        # 把attn_energies从(max_length=10, batch=64)转置成(64, 10)</span><br><span class="line">        attn_energies = attn_energies.t()</span><br><span class="line"></span><br><span class="line">        # 使用softmax函数把score变成概率，shape仍然是(64, 10)，然后用unsqueeze(1)变成</span><br><span class="line">        # (64, 1, 10) </span><br><span class="line">        return F.softmax(attn_energies, dim=1).unsqueeze(1)</span><br></pre></td></tr></table></figure>

<p>上面的代码实现了dot、general和concat三种score计算方法，分别和前面的三个公式对应，我们这里介绍最简单的dot方法。代码里也有一些注释，只有dot_score函数比较难以理解，我们来分析一下。首先这个函数的输入输入hidden的shape是(1, batch&#x3D;64, hidden_size&#x3D;500)，encoder_outputs的shape是(input_lengths&#x3D;10, batch&#x3D;64, hidden_size&#x3D;500)。</p>
<p>怎么计算hidden和10个encoder输出向量的内积呢？为了简便，我们先假设batch是1，这样可以把第二维(batch维)去掉，因此hidden是(1, 500)，而encoder_outputs是(10, 500)。内积的定义是两个向量对应位相乘然后相加，但是encoder_outputs是10个500维的向量。当然我们可以写一个for循环来计算，但是效率很低。这里用到一个小的技巧，利用broadcasting，hidden * encoder_outputs可以理解为把hidden从(1,500)复制成(10, 500)（当然实际实现并不会这么做），然后两个(10, 500)的矩阵进行乘法。注意，这里的乘法不是矩阵乘法，而是所谓的Hadamard乘法，其实就是把对应位置的乘起来，比如下面的例子：</p>
<p>[142536]∗[121212]&#x3D;[1∗14∗22∗15∗23∗16∗2][123456]∗[111222]&#x3D;[1∗12∗13∗14∗25∗26∗2]</p>
<p>因此hidden * encoder_outputs就可以把hidden向量(500个数)与encoder_outputs的10个向量(500个数)对应的位置相乘。而内积还需要把这500个乘积加起来，因此后面使用torch.sum(hidden * encoder_output, dim&#x3D;2)，把第2维500个乘积加起来，最终得到10个score值。当然我们实际还有一个batch维度，因此最终得到的attn_energies是(10, 64)。接着在forward函数里把attn_energies转置成(64, 10)，然后使用softmax函数把10个score变成概率，shape仍然是(64, 10)，为了后面使用方便，我们用unsqueeze(1)把它变成(64, 1, 10)。</p>
<p>有了注意力的子模块之后，我们就可以实现Decoder了。Encoder可以一次把一个序列输入GRU，得到整个序列的输出。但是Decoder t时刻的输入是t-1时刻的输出，在t-1时刻计算完成之前是未知的，因此只能一次处理一个时刻的数据。因此Encoder的GRU的输入是(max_length, batch, hidden_size)，而Decoder的输入是(1, batch, hidden_size)。此外Decoder只能利用前面的信息，所以只能使用单向(而不是双向)的GRU，而Encoder的GRU是双向的，如果两种的hidden_size是一样的，则Decoder的隐单元个数少了一半，那怎么把Encoder的最后时刻的隐状态作为Decoder的初始隐状态呢？这里是把每个时刻双向结果加起来的，因此它们的大小就能匹配了（请读者参考前面Encoder双向相加的部分代码）。</p>
<p><strong>计算图:</strong></p>
<ol>
<li>把词ID输入Embedding层 2) 使用单向的GRU继续Forward进行一个时刻的计算。 3) 使用新的隐状态计算注意力权重 4) 用注意力权重得到context向量 5) context向量和GRU的输出拼接起来，然后再进过一个全连接网络，使得输出大小仍然是hidden_size 6) 使用一个投影矩阵把输出从hidden_size变成词典大小，然后用softmax变成概率 7) 返回输出和新的隐状态</li>
</ol>
<p><strong>输入:</strong></p>
<ul>
<li><code>input_step</code>: shape是(1, batch_size)</li>
<li><code>last_hidden</code>: 上一个时刻的隐状态， shape是(n_layers x num_directions, batch_size, hidden_size)</li>
<li><code>encoder_outputs</code>: encoder的输出， shape是(max_length, batch_size, hidden_size)</li>
</ul>
<p><strong>输出:</strong></p>
<ul>
<li><code>output</code>: 当前时刻输出每个词的概率，shape是(batch_size, voc.num_words)</li>
<li><code>hidden</code>: 新的隐状态，shape是(n_layers x num_directions, batch_size, hidden_size)</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">class LuongAttnDecoderRNN(nn.Module):</span><br><span class="line">    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):</span><br><span class="line">        super(LuongAttnDecoderRNN, self).__init__()</span><br><span class="line"></span><br><span class="line">        # 保存到self里，attn_model就是前面定义的Attn类的对象。</span><br><span class="line">        self.attn_model = attn_model</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.output_size = output_size</span><br><span class="line">        self.n_layers = n_layers</span><br><span class="line">        self.dropout = dropout</span><br><span class="line"></span><br><span class="line">        # 定义Decoder的layers</span><br><span class="line">        self.embedding = embedding</span><br><span class="line">        self.embedding_dropout = nn.Dropout(dropout)</span><br><span class="line">        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))</span><br><span class="line">        self.concat = nn.Linear(hidden_size * 2, hidden_size)</span><br><span class="line">        self.out = nn.Linear(hidden_size, output_size)</span><br><span class="line"></span><br><span class="line">        self.attn = Attn(attn_model, hidden_size)</span><br><span class="line"></span><br><span class="line">    def forward(self, input_step, last_hidden, encoder_outputs):</span><br><span class="line">        # 注意：decoder每一步只能处理一个时刻的数据，因为t时刻计算完了才能计算t+1时刻。</span><br><span class="line">        # input_step的shape是(1, 64)，64是batch，1是当前输入的词ID(来自上一个时刻的输出)</span><br><span class="line">        # 通过embedding层变成(1, 64, 500)，然后进行dropout，shape不变。</span><br><span class="line">        embedded = self.embedding(input_step)</span><br><span class="line">        embedded = self.embedding_dropout(embedded)</span><br><span class="line">        # 把embedded传入GRU进行forward计算</span><br><span class="line">        # 得到rnn_output的shape是(1, 64, 500)</span><br><span class="line">        # hidden是(2, 64, 500)，因为是两层的GRU，所以第一维是2。</span><br><span class="line">        rnn_output, hidden = self.gru(embedded, last_hidden)</span><br><span class="line">        # 计算注意力权重， 根据前面的分析，attn_weights的shape是(64, 1, 10)</span><br><span class="line">        attn_weights = self.attn(rnn_output, encoder_outputs)</span><br><span class="line">        </span><br><span class="line">        # encoder_outputs是(10, 64, 500) </span><br><span class="line">        # encoder_outputs.transpose(0, 1)后的shape是(64, 10, 500)</span><br><span class="line">        # attn_weights.bmm后是(64, 1, 500)</span><br><span class="line">        </span><br><span class="line">        # bmm是批量的矩阵乘法，第一维是batch，我们可以把attn_weights看成64个(1,10)的矩阵</span><br><span class="line">        # 把encoder_outputs.transpose(0, 1)看成64个(10, 500)的矩阵</span><br><span class="line">        # 那么bmm就是64个(1, 10)矩阵 x (10, 500)矩阵，最终得到(64, 1, 500)</span><br><span class="line">        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))</span><br><span class="line">        # 把context向量和GRU的输出拼接起来</span><br><span class="line">        # rnn_output从(1, 64, 500)变成(64, 500)</span><br><span class="line">        rnn_output = rnn_output.squeeze(0)</span><br><span class="line">        # context从(64, 1, 500)变成(64, 500)</span><br><span class="line">        context = context.squeeze(1)</span><br><span class="line">        # 拼接得到(64, 1000)</span><br><span class="line">        concat_input = torch.cat((rnn_output, context), 1)</span><br><span class="line">        # self.concat是一个矩阵(1000, 500)，</span><br><span class="line">        # self.concat(concat_input)的输出是(64, 500)</span><br><span class="line">        # 然后用tanh把输出返回变成(-1,1)，concat_output的shape是(64, 500)</span><br><span class="line">        concat_output = torch.tanh(self.concat(concat_input))</span><br><span class="line"></span><br><span class="line">        # out是(500, 词典大小=7826)    </span><br><span class="line">        output = self.out(concat_output)</span><br><span class="line">        # 用softmax变成概率，表示当前时刻输出每个词的概率。</span><br><span class="line">        output = F.softmax(output, dim=1)</span><br><span class="line">        # 返回 output和新的隐状态 </span><br><span class="line">        return output, hidden</span><br></pre></td></tr></table></figure>

<h2 id="定义训练过程"><a href="#定义训练过程" class="headerlink" title="定义训练过程"></a>定义训练过程</h2><h3 id="Masked损失"><a href="#Masked损失" class="headerlink" title="Masked损失"></a>Masked损失</h3><p>forward实现之后，我们就需要计算loss。seq2seq有两个RNN，Encoder RNN是没有直接定义损失函数的，它是通过影响Decoder从而影响最终的输出以及loss。Decoder输出一个序列，前面我们介绍的是Decoder在预测时的过程，它的长度是不固定的，只有遇到EOS才结束。给定一个问答句对，我们可以把问题输入Encoder，然后用Decoder得到一个输出序列，但是这个输出序列和”真实”的答案长度并不相同。</p>
<p>而且即使长度相同并且语义相似，也很难直接知道预测的答案和真实的答案是否类似。那么我们怎么计算loss呢？比如输入是”What is your name?”，训练数据中的答案是”I am LiLi”。假设模型有两种预测：”I am fine”和”My name is LiLi”。从语义上显然第二种答案更好，但是如果字面上比较的话可能第一种更好。</p>
<p>但是让机器知道”I am LiLi”和”My name is LiLi”的语义很接近这是非常困难的，所以实际上我们通常还是通过字面上里进行比较。我们会限制Decoder的输出，使得Decoder的输出长度和”真实”答案一样，然后逐个时刻比较。Decoder输出的是每个词的概率分布，因此可以使用交叉熵损失函数。但是这里还有一个问题，因为是一个batch的数据里有一些是padding的，因此这些位置的预测是没有必要计算loss的，因此我们需要使用前面的mask矩阵把对应位置的loss去掉，我们可以通过下面的函数来实现计算Masked的loss。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def maskNLLLoss(inp, target, mask):</span><br><span class="line">    # 计算实际的词的个数，因为padding是0，非padding是1，因此sum就可以得到词的个数</span><br><span class="line">    nTotal = mask.sum()</span><br><span class="line">    </span><br><span class="line">    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))</span><br><span class="line">    loss = crossEntropy.masked_select(mask).mean()</span><br><span class="line">    loss = loss.to(device)</span><br><span class="line">    return loss, nTotal.item()</span><br></pre></td></tr></table></figure>

<p>上面的代码有几个需要注意的地方。首先是masked_select函数，我们来看一个例子：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = torch.randn(3, 4)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">tensor([[ 0.3552, -2.3825, -0.8297,  0.3477],</span><br><span class="line">        [-1.2035,  1.2252,  0.5002,  0.6248],</span><br><span class="line">        [ 0.1307, -2.0608,  0.1244,  2.0139]])</span><br><span class="line">&gt;&gt;&gt; mask = x.ge(0.5)</span><br><span class="line">&gt;&gt;&gt; mask</span><br><span class="line">tensor([[ 0,  0,  0,  0],</span><br><span class="line">        [ 0,  1,  1,  1],</span><br><span class="line">        [ 0,  0,  0,  1]], dtype=torch.uint8)</span><br><span class="line">&gt;&gt;&gt; torch.masked_select(x, mask)</span><br><span class="line">tensor([ 1.2252,  0.5002,  0.6248,  2.0139])</span><br></pre></td></tr></table></figure>

<p>它要求mask和被mask的tensor的shape是一样的，然后从crossEntropy选出mask值为1的那些值。输出的维度会减1。</p>
<p>另外为了实现交叉熵这里使用了gather函数，这是一种比较底层的实现方法，更简便的方法应该使用CrossEntropyLoss或者NLLLoss，其中CrossEntropy等价与LogSoftmax+NLLLoss。</p>
<p>交叉熵的定义为：𝐻(𝑝,𝑞)&#x3D;−∑𝑥𝑝(𝑥)𝑙𝑜𝑔𝑞(𝑥)�(�,�)&#x3D;−∑��(�)����(�)。其中p和q是两个随机变量的概率分布，这里是离散的随机变量，如果是连续的需要把求和变成积分。在我们这里p是真实的分布，也就是one-hot的，而q是模型预测的softmax的输出。因为p是one-hot的，所以只需要计算真实分类对应的那个值。</p>
<p>比如假设一个5分类的问题，当前正确分类是2(下标从0-4)，而模型的预测是(0.1,0.1,0.4,0.2,0.2)，则H&#x3D;-log(0.4)。用交叉熵作为分类的Loss是比较合理的，正确的分类是2，那么模型在下标为2的地方预测的概率𝑞2�2越大，则−𝑙𝑜𝑔𝑞2−����2越小，也就是loss越小。</p>
<p>假设inp是：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0.3 0.2 0.4 0.1</span><br><span class="line">0.2 0.1 0.4 0.3</span><br></pre></td></tr></table></figure>

<p>也就是batch&#x3D;2，而分类数(词典大小)是4，inp是模型预测的分类概率。 而target &#x3D; [2,3] ，表示第一个样本的正确分类是第三个类别(概率是0.4），第二个样本的正确分类是第四个类别(概率是0.3)。因此我们需要计算的是 -log(0.4) - log(0.3)。怎么不用for循环求出来呢？我们可以使用torch.gather函数首先把0.4和0.3选出来：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">inp = torch.tensor([[0.3, 0.2, 0.4, 0.1], [0.2, 0.1, 0.4, 0.3]])</span><br><span class="line">target = torch.tensor([2, 3])</span><br><span class="line">selected = torch.gather(inp, 1, target.view(-1, 1))</span><br><span class="line">print(selected)</span><br><span class="line">输出：</span><br><span class="line">tensor([[ 0.4000],</span><br><span class="line">        [ 0.3000]])</span><br></pre></td></tr></table></figure>

<h3 id="一次迭代的训练过程"><a href="#一次迭代的训练过程" class="headerlink" title="一次迭代的训练过程"></a>一次迭代的训练过程</h3><p>函数<code>train</code>实现一个batch数据的训练。前面我们提到过，在训练的时候我们会限制Decoder的输出，使得Decoder的输出长度和”真实”答案一样长。但是我们在训练的时候如果让Decoder自行输出，那么收敛可能会比较慢，因为Decoder在t时刻的输入来自t-1时刻的输出。如果前面预测错了，那么后面很可能都会错下去。另外一种方法叫做<strong>teacher forcing</strong>，它不管模型在t-1时刻做什么预测都把t-1时刻的正确答案作为t时刻的输入。但是如果只用teacher forcing也有问题，因为在真实的Decoder的是是没有老师来帮它纠正错误的。所以比较好的方法是更加一个teacher_forcing_ratio参数随机的来确定本次训练是否teacher forcing。</p>
<p>另外使用到的一个技巧是<strong>梯度裁剪(gradient clipping)</strong> 。这个技巧通常是为了防止梯度爆炸(exploding gradient)，它把参数限制在一个范围之内，从而可以避免梯度的梯度过大或者出现NaN等问题。注意：虽然它的名字叫梯度裁剪，但实际它是对模型的参数进行裁剪，它把整个参数看成一个向量，如果这个向量的模大于max_norm，那么就把这个向量除以一个值使得模等于max_norm，因此也等价于把这个向量投影到半径为max_norm的球上。它的效果如下图所示。</p>
<p><img src="https://fancyerii.github.io/img/chatbot/grad_clip.png" alt="img"></p>
<p><strong>操作步骤:</strong></p>
<ol>
<li>把整个batch的输入传入encoder 2) 把decoder的输入设置为特殊的，初始隐状态设置为encoder最后时刻的隐状态 3) decoder每次处理一个时刻的forward计算 4) 如果是teacher forcing，把上个时刻的”正确的”词作为当前输入，否则用上一个时刻的输出作为当前时刻的输入 5) 计算loss 6) 反向计算梯度 7) 对梯度进行裁剪 8) 更新模型(包括encoder和decoder)参数</li>
</ol>
<p>注意，PyTorch的RNN模块(<code>RNN</code>, <code>LSTM</code>, <code>GRU</code>)也可以当成普通的非循环的网络来使用。在Encoder部分，我们是直接把所有时刻的数据都传入RNN，让它一次计算出所有的结果，但是在Decoder的时候(非teacher forcing)后一个时刻的输入来自前一个时刻的输出，因此无法一次计算。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,</span><br><span class="line">          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):</span><br><span class="line"></span><br><span class="line">    # 梯度清空</span><br><span class="line">    encoder_optimizer.zero_grad()</span><br><span class="line">    decoder_optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    # 设置device，从而支持GPU，当然如果没有GPU也能工作。</span><br><span class="line">    input_variable = input_variable.to(device)</span><br><span class="line">    lengths = lengths.to(device)</span><br><span class="line">    target_variable = target_variable.to(device)</span><br><span class="line">    mask = mask.to(device)</span><br><span class="line"></span><br><span class="line">    # 初始化变量</span><br><span class="line">    loss = 0</span><br><span class="line">    print_losses = []</span><br><span class="line">    n_totals = 0</span><br><span class="line"></span><br><span class="line">    # encoder的Forward计算</span><br><span class="line">    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)</span><br><span class="line"></span><br><span class="line">    # Decoder的初始输入是SOS，我们需要构造(1, batch)的输入，表示第一个时刻batch个输入。</span><br><span class="line">    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])</span><br><span class="line">    decoder_input = decoder_input.to(device)</span><br><span class="line"></span><br><span class="line">    # 注意：Encoder是双向的，而Decoder是单向的，因此从下往上取n_layers个</span><br><span class="line">    decoder_hidden = encoder_hidden[:decoder.n_layers]</span><br><span class="line"></span><br><span class="line">    # 确定是否teacher forcing</span><br><span class="line">    use_teacher_forcing = True if random.random() &lt; teacher_forcing_ratio else False</span><br><span class="line"></span><br><span class="line">    # 一次处理一个时刻 </span><br><span class="line">    if use_teacher_forcing:</span><br><span class="line">        for t in range(max_target_len):</span><br><span class="line">            decoder_output, decoder_hidden = decoder(</span><br><span class="line">                decoder_input, decoder_hidden, encoder_outputs</span><br><span class="line">            )</span><br><span class="line">            # Teacher forcing: 下一个时刻的输入是当前正确答案</span><br><span class="line">            decoder_input = target_variable[t].view(1, -1)</span><br><span class="line">            # 计算累计的loss</span><br><span class="line">            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])</span><br><span class="line">            loss += mask_loss</span><br><span class="line">            print_losses.append(mask_loss.item() * nTotal)</span><br><span class="line">            n_totals += nTotal</span><br><span class="line">    else:</span><br><span class="line">        for t in range(max_target_len):</span><br><span class="line">            decoder_output, decoder_hidden = decoder(</span><br><span class="line">                decoder_input, decoder_hidden, encoder_outputs</span><br><span class="line">            )</span><br><span class="line">            # 不是teacher forcing: 下一个时刻的输入是当前模型预测概率最高的值</span><br><span class="line">            _, topi = decoder_output.topk(1)</span><br><span class="line">            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])</span><br><span class="line">            decoder_input = decoder_input.to(device)</span><br><span class="line">            # 计算累计的loss</span><br><span class="line">            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])</span><br><span class="line">            loss += mask_loss</span><br><span class="line">            print_losses.append(mask_loss.item() * nTotal)</span><br><span class="line">            n_totals += nTotal</span><br><span class="line"></span><br><span class="line">    # 反向计算 </span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    # 对encoder和decoder进行梯度裁剪</span><br><span class="line">    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)</span><br><span class="line">    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)</span><br><span class="line"></span><br><span class="line">    # 更新参数</span><br><span class="line">    encoder_optimizer.step()</span><br><span class="line">    decoder_optimizer.step()</span><br><span class="line"></span><br><span class="line">    return sum(print_losses) / n_totals</span><br></pre></td></tr></table></figure>

<h3 id="训练迭代过程"><a href="#训练迭代过程" class="headerlink" title="训练迭代过程"></a>训练迭代过程</h3><p>最后是把前面的代码组合起来进行训练。函数<code>trainIters</code>用于进行<code>n_iterations</code>次minibatch的训练。</p>
<p>值得注意的是我们定期会保存模型，我们会保存一个tar包，包括encoder和decoder的state_dicts(参数),优化器(optimizers)的state_dicts, loss和迭代次数。这样保存模型的好处是从中恢复后我们既可以进行预测也可以进行训练(因为有优化器的参数和迭代的次数)。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, </span><br><span class="line">              embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, </span><br><span class="line">              print_every, save_every, clip, corpus_name, loadFilename):</span><br><span class="line"></span><br><span class="line">    # 随机选择n_iteration个batch的数据(pair)</span><br><span class="line">    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])</span><br><span class="line">                      for _ in range(n_iteration)]</span><br><span class="line"></span><br><span class="line">    # 初始化</span><br><span class="line">    print(&#x27;Initializing ...&#x27;)</span><br><span class="line">    start_iteration = 1</span><br><span class="line">    print_loss = 0</span><br><span class="line">    if loadFilename:</span><br><span class="line">        start_iteration = checkpoint[&#x27;iteration&#x27;] + 1</span><br><span class="line"></span><br><span class="line">    # 训练</span><br><span class="line">    print(&quot;Training...&quot;)</span><br><span class="line">    for iteration in range(start_iteration, n_iteration + 1):</span><br><span class="line">        training_batch = training_batches[iteration - 1]</span><br><span class="line">        </span><br><span class="line">        input_variable, lengths, target_variable, mask, max_target_len = training_batch</span><br><span class="line"></span><br><span class="line">        # 训练一个batch的数据</span><br><span class="line">        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,</span><br><span class="line">                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)</span><br><span class="line">        print_loss += loss</span><br><span class="line"></span><br><span class="line">        # 进度</span><br><span class="line">        if iteration % print_every == 0:</span><br><span class="line">            print_loss_avg = print_loss / print_every</span><br><span class="line">            print(&quot;Iteration: &#123;&#125;; Percent complete: &#123;:.1f&#125;%; Average loss: &#123;:.4f&#125;&quot;</span><br><span class="line">			.format(iteration, iteration / n_iteration * 100, print_loss_avg))</span><br><span class="line">            print_loss = 0</span><br><span class="line"></span><br><span class="line">        # 保存checkpoint</span><br><span class="line">        if (iteration % save_every == 0):</span><br><span class="line">            directory = os.path.join(save_dir, model_name, corpus_name, &#x27;&#123;&#125;-&#123;&#125;_&#123;&#125;&#x27;</span><br><span class="line">		.format(encoder_n_layers, decoder_n_layers, hidden_size))</span><br><span class="line">            if not os.path.exists(directory):</span><br><span class="line">                os.makedirs(directory)</span><br><span class="line">            torch.save(&#123;</span><br><span class="line">                &#x27;iteration&#x27;: iteration,</span><br><span class="line">                &#x27;en&#x27;: encoder.state_dict(),</span><br><span class="line">                &#x27;de&#x27;: decoder.state_dict(),</span><br><span class="line">                &#x27;en_opt&#x27;: encoder_optimizer.state_dict(),</span><br><span class="line">                &#x27;de_opt&#x27;: decoder_optimizer.state_dict(),</span><br><span class="line">                &#x27;loss&#x27;: loss,</span><br><span class="line">                &#x27;voc_dict&#x27;: voc.__dict__,</span><br><span class="line">                &#x27;embedding&#x27;: embedding.state_dict()</span><br><span class="line">            &#125;, os.path.join(directory, &#x27;&#123;&#125;_&#123;&#125;.tar&#x27;.format(iteration, &#x27;checkpoint&#x27;)))</span><br></pre></td></tr></table></figure>

<h2 id="效果测试"><a href="#效果测试" class="headerlink" title="效果测试"></a>效果测试</h2><p>模型训练完成之后，我们需要测试它的效果。最简单直接的方法就是和chatbot来聊天。因此我们需要用Decoder来生成一个响应。</p>
<h3 id="贪心解码-Greedy-decoding-算法"><a href="#贪心解码-Greedy-decoding-算法" class="headerlink" title="贪心解码(Greedy decoding)算法"></a>贪心解码(Greedy decoding)算法</h3><p>最简单的解码算法是贪心算法，也就是每次都选择概率最高的那个词，然后把这个词作为下一个时刻的输入，直到遇到EOS结束解码或者达到一个最大长度。但是贪心算法不一定能得到最优解，因为某个答案可能开始的几个词的概率并不太高，但是后来概率会很大。因此除了贪心算法，我们通常也可以使用Beam-Search算法，也就是每个时刻保留概率最高的Top K个结果，然后下一个时刻尝试把这K个结果输入(当然需要能恢复RNN的状态)，然后再从中选择概率最高的K个。</p>
<p>为了实现贪心解码算法，我们定义一个<code>GreedySearchDecoder</code>类。这个类的forwar的方法需要传入一个输入序列(<code>input_seq</code>)，其shape是(input_seq length, 1)， 输入长度input_length和最大输出长度<code>max_length</code>。就是过程如下：</p>
<ol>
<li>把输入传给Encoder，得到所有时刻的输出和最后一个时刻的隐状态。 2) 把Encoder最后时刻的隐状态作为Decoder的初始状态。 3) Decoder的第一输入初始化为SOS。 4) 定义保存解码结果的tensor 5) 循环直到最大解码长度 a) 把当前输入传入Decoder b) 得到概率最大的词以及概率 c) 把这个词和概率保存下来 d) 把当前输出的词作为下一个时刻的输入 6) 返回所有的词和概率</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">class GreedySearchDecoder(nn.Module):</span><br><span class="line">    def __init__(self, encoder, decoder):</span><br><span class="line">        super(GreedySearchDecoder, self).__init__()</span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder</span><br><span class="line"></span><br><span class="line">    def forward(self, input_seq, input_length, max_length):</span><br><span class="line">        # Encoder的Forward计算 </span><br><span class="line">        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)</span><br><span class="line">        # 把Encoder最后时刻的隐状态作为Decoder的初始值</span><br><span class="line">        decoder_hidden = encoder_hidden[:decoder.n_layers]</span><br><span class="line">        # 因为我们的函数都是要求(time,batch)，因此即使只有一个数据，也要做出二维的。</span><br><span class="line">        # Decoder的初始输入是SOS</span><br><span class="line">        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token</span><br><span class="line">        # 用于保存解码结果的tensor</span><br><span class="line">        all_tokens = torch.zeros([0], device=device, dtype=torch.long)</span><br><span class="line">        all_scores = torch.zeros([0], device=device)</span><br><span class="line">        # 循环，这里只使用长度限制，后面处理的时候把EOS去掉了。</span><br><span class="line">        for _ in range(max_length):</span><br><span class="line">            # Decoder forward一步</span><br><span class="line">            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, </span><br><span class="line">								encoder_outputs)</span><br><span class="line">            # decoder_outputs是(batch=1, vob_size)</span><br><span class="line">            # 使用max返回概率最大的词和得分</span><br><span class="line">            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)</span><br><span class="line">            # 把解码结果保存到all_tokens和all_scores里</span><br><span class="line">            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)</span><br><span class="line">            all_scores = torch.cat((all_scores, decoder_scores), dim=0)</span><br><span class="line">            # decoder_input是当前时刻输出的词的ID，这是个一维的向量，因为max会减少一维。</span><br><span class="line">            # 但是decoder要求有一个batch维度，因此用unsqueeze增加batch维度。</span><br><span class="line">            decoder_input = torch.unsqueeze(decoder_input, 0)</span><br><span class="line">        # 返回所有的词和得分。</span><br><span class="line">        return all_tokens, all_scores</span><br></pre></td></tr></table></figure>

<h3 id="测试对话函数"><a href="#测试对话函数" class="headerlink" title="测试对话函数"></a>测试对话函数</h3><p>解码方法完成后，我们写一个函数来测试从终端输入一个句子然后来看看chatbot的回复。我们需要用前面的函数来把句子分词，然后变成ID传入解码器，得到输出的ID后再转换成文字。我们会实现一个<code>evaluate</code>函数，由它来完成这些工作。我们需要把一个句子变成输入需要的格式——shape为(batch, max_length)，即使只有一个输入也需要增加一个batch维度。我们首先把句子分词，然后变成ID的序列，然后转置成合适的格式。此外我们还需要创建一个名为<code>lengths</code>的tensor，虽然只有一个，来表示输入的实际长度。接着我们构造类<code>GreedySearchDecoder</code>的实例<code>searcher</code>，然后用searcher来进行解码得到输出的ID，最后我们把这些ID变成词并且去掉EOS之后的内容。</p>
<p>另外一个<code>evaluateInput</code>函数作为chatbot的用户接口，当运行它的时候，它会首先提示用户输入一个句子，然后使用<code>evaluate</code>来生成回复。然后继续对话直到用户输入”q”或者”quit”。如果用户输入的词不在词典里，我们会输出错误信息(当然还有一种办法是忽略这些词)然后提示用户重新输入。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):</span><br><span class="line">    ### 把输入的一个batch句子变成id</span><br><span class="line">    indexes_batch = [indexesFromSentence(voc, sentence)]</span><br><span class="line">    # 创建lengths tensor</span><br><span class="line">    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])</span><br><span class="line">    # 转置 </span><br><span class="line">    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)</span><br><span class="line">    # 放到合适的设备上(比如GPU)</span><br><span class="line">    input_batch = input_batch.to(device)</span><br><span class="line">    lengths = lengths.to(device)</span><br><span class="line">    # 用searcher解码</span><br><span class="line">    tokens, scores = searcher(input_batch, lengths, max_length)</span><br><span class="line">    # ID变成词。</span><br><span class="line">    decoded_words = [voc.index2word[token.item()] for token in tokens]</span><br><span class="line">    return decoded_words</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def evaluateInput(encoder, decoder, searcher, voc):</span><br><span class="line">    input_sentence = &#x27;&#x27;</span><br><span class="line">    while(1):</span><br><span class="line">        try:</span><br><span class="line">            # 得到用户终端的输入</span><br><span class="line">            input_sentence = input(&#x27;&gt; &#x27;)</span><br><span class="line">            # 是否退出</span><br><span class="line">            if input_sentence == &#x27;q&#x27; or input_sentence == &#x27;quit&#x27;: break</span><br><span class="line">            # 句子归一化</span><br><span class="line">            input_sentence = normalizeString(input_sentence)</span><br><span class="line">            # 生成响应Evaluate sentence</span><br><span class="line">            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)</span><br><span class="line">            # 去掉EOS后面的内容</span><br><span class="line">            words = []</span><br><span class="line">            for word in output_words:</span><br><span class="line">                if word == &#x27;EOS&#x27;:</span><br><span class="line">                    break</span><br><span class="line">                elif word != &#x27;PAD&#x27;:</span><br><span class="line">                    words.append(word)</span><br><span class="line">            print(&#x27;Bot:&#x27;, &#x27; &#x27;.join(words))</span><br><span class="line"></span><br><span class="line">        except KeyError:</span><br><span class="line">            print(&quot;Error: Encountered unknown word.&quot;)</span><br><span class="line">      </span><br></pre></td></tr></table></figure>

<h2 id="训练和测试模型"><a href="#训练和测试模型" class="headerlink" title="训练和测试模型"></a>训练和测试模型</h2><p>最后我们可以来训练模型和进行评测了。</p>
<p>不论是我们像训练模型还是测试对话，我们都需要初始化encoder和decoder模型参数。在下面的代码，我们从头开始训练模型或者从某个checkpoint加载模型。读者可以尝试不同的超参数配置来进行调优。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"># 配置模型</span><br><span class="line">model_name = &#x27;cb_model&#x27;</span><br><span class="line">attn_model = &#x27;dot&#x27;</span><br><span class="line">#attn_model = &#x27;general&#x27;</span><br><span class="line">#attn_model = &#x27;concat&#x27;</span><br><span class="line">hidden_size = 500</span><br><span class="line">encoder_n_layers = 2</span><br><span class="line">decoder_n_layers = 2</span><br><span class="line">dropout = 0.1</span><br><span class="line">batch_size = 64</span><br><span class="line"></span><br><span class="line"># 从哪个checkpoint恢复，如果是None，那么从头开始训练。</span><br><span class="line">loadFilename = None</span><br><span class="line">checkpoint_iter = 4000</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># 如果loadFilename不空，则从中加载模型 </span><br><span class="line">if loadFilename:</span><br><span class="line">    # 如果训练和加载是一条机器，那么直接加载 </span><br><span class="line">    checkpoint = torch.load(loadFilename)</span><br><span class="line">    # 否则比如checkpoint是在GPU上得到的，但是我们现在又用CPU来训练或者测试，那么注释掉下面的代码</span><br><span class="line">    #checkpoint = torch.load(loadFilename, map_location=torch.device(&#x27;cpu&#x27;))</span><br><span class="line">    encoder_sd = checkpoint[&#x27;en&#x27;]</span><br><span class="line">    decoder_sd = checkpoint[&#x27;de&#x27;]</span><br><span class="line">    encoder_optimizer_sd = checkpoint[&#x27;en_opt&#x27;]</span><br><span class="line">    decoder_optimizer_sd = checkpoint[&#x27;de_opt&#x27;]</span><br><span class="line">    embedding_sd = checkpoint[&#x27;embedding&#x27;]</span><br><span class="line">    voc.__dict__ = checkpoint[&#x27;voc_dict&#x27;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(&#x27;Building encoder and decoder ...&#x27;)</span><br><span class="line"># 初始化word embedding</span><br><span class="line">embedding = nn.Embedding(voc.num_words, hidden_size)</span><br><span class="line">if loadFilename:</span><br><span class="line">    embedding.load_state_dict(embedding_sd)</span><br><span class="line"># 初始化encoder和decoder模型</span><br><span class="line">encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)</span><br><span class="line">decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, </span><br><span class="line">				decoder_n_layers, dropout)</span><br><span class="line">if loadFilename:</span><br><span class="line">    encoder.load_state_dict(encoder_sd)</span><br><span class="line">    decoder.load_state_dict(decoder_sd)</span><br><span class="line"># 使用合适的设备</span><br><span class="line">encoder = encoder.to(device)</span><br><span class="line">decoder = decoder.to(device)</span><br><span class="line">print(&#x27;Models built and ready to go!&#x27;)</span><br></pre></td></tr></table></figure>

<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>下面的代码进行训练，我们需要设置一些训练的超参数。初始化优化器，最后调用函数<code>trainIters</code>进行训练。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># 配置训练的超参数和优化器 </span><br><span class="line">clip = 50.0</span><br><span class="line">teacher_forcing_ratio = 1.0</span><br><span class="line">learning_rate = 0.0001</span><br><span class="line">decoder_learning_ratio = 5.0</span><br><span class="line">n_iteration = 4000</span><br><span class="line">print_every = 1</span><br><span class="line">save_every = 500</span><br><span class="line"></span><br><span class="line"># 设置进入训练模式，从而开启dropout </span><br><span class="line">encoder.train()</span><br><span class="line">decoder.train()</span><br><span class="line"></span><br><span class="line"># 初始化优化器 </span><br><span class="line">print(&#x27;Building optimizers ...&#x27;)</span><br><span class="line">encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)</span><br><span class="line">decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)</span><br><span class="line">if loadFilename:</span><br><span class="line">    encoder_optimizer.load_state_dict(encoder_optimizer_sd)</span><br><span class="line">    decoder_optimizer.load_state_dict(decoder_optimizer_sd)</span><br><span class="line"></span><br><span class="line"># 开始训练</span><br><span class="line">print(&quot;Starting Training!&quot;)</span><br><span class="line">trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,</span><br><span class="line">           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,</span><br><span class="line">           print_every, save_every, clip, corpus_name, loadFilename)</span><br></pre></td></tr></table></figure>

<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>我们使用下面的代码进行测试。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 进入eval模式，从而去掉dropout。 </span><br><span class="line">encoder.eval()</span><br><span class="line">decoder.eval()</span><br><span class="line"></span><br><span class="line"># 构造searcher对象 </span><br><span class="line">searcher = GreedySearchDecoder(encoder, decoder)</span><br><span class="line"></span><br><span class="line"># 测试</span><br><span class="line">evaluateInput(encoder, decoder, searcher, voc)</span><br></pre></td></tr></table></figure>

<p>下面是测试的一些例子：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt; hello</span><br><span class="line">Bot: hello .</span><br><span class="line">&gt; what&#x27;s your name?</span><br><span class="line">Bot: jacob .</span><br><span class="line">&gt; I am sorry.</span><br><span class="line">Bot: you re not .</span><br><span class="line">&gt; where are you from?</span><br><span class="line">Bot: southern .</span><br><span class="line">&gt; q</span><br></pre></td></tr></table></figure>

<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>上面介绍了怎么从零开始训练一个chatbot，读者可以用自己的数据训练一个chatbot试试，看看能不能用来解决一些实际业务问题。</p>
<hr>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://fancyerii.github.io/2019/02/19/mvn-error/">NEXT POST →</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://fancyerii.github.io/2019/02/14/chatbot/">显示DISQUS评论(需要科学上网)</a></p>
</li>
</ul>
<hr>
<h5 id="FEATURED-TAGS"><a href="#FEATURED-TAGS" class="headerlink" title="FEATURED TAGS"></a><a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/">FEATURED TAGS</a></h5><p><a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD">人工智能</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">深度学习</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#chatbot">chatbot</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#PyTorch">PyTorch</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#Java">Java</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#BERT">BERT</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#git">git</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#%E7%BC%96%E7%A8%8B">编程</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#OCR">OCR</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#%E6%B1%AA%E6%9B%BE%E7%A5%BA">汪曾祺</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB">语音识别</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#Kaldi">Kaldi</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#Linux">Linux</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#XLNet">XLNet</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90">情感分析</a> [sentiment analysis](<a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#sentiment">https://fancyerii.github.io/tags/#sentiment</a> analysis) <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#%E8%AF%AD%E6%B3%95%E7%BA%A0%E9%94%99">语法纠错</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#Transformer">Transformer</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#Tensorflow">Tensorflow</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#Huggingface">Huggingface</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#Ubuntu">Ubuntu</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#TensorFlow">TensorFlow</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6">深度学习框架</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#Tensor2Tensor">Tensor2Tensor</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91">机器翻译</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#%E5%BE%AE%E4%BF%A1">微信</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#wechat">wechat</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#automation">automation</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#selenium">selenium</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#webdriver">webdriver</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#pywinauto">pywinauto</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#CentOS">CentOS</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#GPU">GPU</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#Appium">Appium</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#t2t">t2t</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB">代码阅读</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#%E4%B8%AD%E8%8B%B1%E7%BF%BB%E8%AF%91">中英翻译</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#%E5%85%AC%E4%BC%97%E5%8F%B7">公众号</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#%E7%88%AC%E8%99%AB">爬虫</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#ocr">ocr</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#tesseract">tesseract</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#pytesseract">pytesseract</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#python">python</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#%E9%BB%98%E8%AE%A4%E5%8F%82%E6%95%B0">默认参数</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#%E4%BD%8D%E7%BD%AE%E5%8F%82%E6%95%B0">位置参数</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#VPN">VPN</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#JSON">JSON</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#Jackson">Jackson</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#huggingface">huggingface</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#PagedAttention">PagedAttention</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#vLLM">vLLM</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#Pre-training">Pre-training</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#LLM">LLM</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#CPT">CPT</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#qlora">qlora</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#quantization">quantization</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#transformers">transformers</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#cmake">cmake</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#pip">pip</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#pipenv">pipenv</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#conda">conda</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#padding">padding</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#vscode">vscode</a> [source code](<a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#source">https://fancyerii.github.io/tags/#source</a> code) <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#build">build</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#Speech">Speech</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#ASR">ASR</a> <a target="_blank" rel="noopener" href="https://fancyerii.github.io/tags/#linux">linux</a></p>
<hr>
<h5 id="FRIENDS"><a href="#FRIENDS" class="headerlink" title="FRIENDS"></a>FRIENDS</h5><ul>
<li><p><a target="_blank" rel="noopener" href="http://fancyerii.github.io/">Li Li</a></p>
</li>
<li></li>
<li></li>
<li></li>
<li></li>
<li><p><a target="_blank" rel="noopener" href="https://fancyerii.github.io/site.txt">
</a></p>
</li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>AI Chat Bot</p><p><a href="http://example.com/2024/03/13/AI Chat Bot/">http://example.com/2024/03/13/AI Chat Bot/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>OnlyourMiracle</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2024-03-13</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2024-03-20</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/AI/">AI</a></div><div class="a2a_kit a2a_kit_size_32 a2a_default_style"><a class="a2a_dd" target="_blank" rel="noopener" href="https://www.addtoany.com/share"></a><a class="a2a_button_facebook"></a><a class="a2a_button_twitter"></a><a class="a2a_button_telegram"></a><a class="a2a_button_whatsapp"></a><a class="a2a_button_reddit"></a></div><script src="https://static.addtoany.com/menu/page.js" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2024/03/20/ChatBot%20Training%20Tour/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">ChatBot Training Tour</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2023/12/30/%E5%A4%A7%E9%81%93/"><span class="level-item">大道</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/disqusjs@1.3.0/dist/disqusjs.css"><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script src="https://cdn.jsdelivr.net/npm/disqusjs@1.3.0/dist/disqus.js"></script><script>new DisqusJS({
            shortname: 'my-hexo-blog-1',
            apikey: "oWUQ2a5UGyr4N1tQF7JuKw6RZINuwstmRlI2oAxwbmiIcZ0YWPK95jGGu07cQSxs",
            siteName: "OnlyourMiracle",
            identifier: "2024/03/13/AI Chat Bot/",
            url: "http://example.com/2024/03/13/AI%20Chat%20Bot/",
            title: "AI Chat Bot",
            
            
            
            
        });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/download/DragonLogo.jpeg" alt="OnlyourMiracle"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">OnlyourMiracle</p><p class="is-size-6 is-block">历尽千帆仍少年</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">21</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">6</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">6</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ONLYOURMIRACLE" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ONLYOURMIRACLE"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/onlyourmiracle"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/OnlyourMiracle"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com/OnlyourMiracle"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">December 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">June 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/AI/"><span class="level-start"><span class="level-item">AI</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Computer-science/"><span class="level-start"><span class="level-item">Computer science</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Knowledge/"><span class="level-start"><span class="level-item">Knowledge</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Life-experience/"><span class="level-start"><span class="level-item">Life experience</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Reading/"><span class="level-start"><span class="level-item">Reading</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Reading-notes/"><span class="level-start"><span class="level-item">Reading notes</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-03-29T11:05:18.688Z">2024-03-29</time></p><p class="title"><a href="/2024/03/29/AI%20Project/">AI Project</a></p><p class="categories"><a href="/categories/AI/">AI</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-03-24T07:34:49.183Z">2024-03-24</time></p><p class="title"><a href="/2024/03/24/Pytorch%20Learning%20Tour/">Pytorch Learning Tour</a></p><p class="categories"><a href="/categories/AI/">AI</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-03-20T13:48:47.057Z">2024-03-20</time></p><p class="title"><a href="/2024/03/20/ChatBot%20Training%20Tour/">ChatBot Training Tour</a></p><p class="categories"><a href="/categories/AI/">AI</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-03-13T13:29:55.798Z">2024-03-13</time></p><p class="title"><a href="/2024/03/13/AI%20Chat%20Bot/">AI Chat Bot</a></p><p class="categories"><a href="/categories/AI/">AI</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-30T10:48:37.761Z">2023-12-30</time></p><p class="title"><a href="/2023/12/30/%E5%A4%A7%E9%81%93/">大道</a></p><p class="categories"><a href="/categories/Reading/">Reading</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-science/"><span class="tag">Computer science</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Knowledge/"><span class="tag">Knowledge</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Life-experience/"><span class="tag">Life experience</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reading/"><span class="tag">Reading</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reading-notes/"><span class="tag">Reading notes</span><span class="tag">9</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/download/DragonLogo2.png" alt="OnlyourMiracle" height="28"></a><p class="is-size-7"><span>&copy; 2025 OnlyourMiracle</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ONLYOURMIRACLE"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>