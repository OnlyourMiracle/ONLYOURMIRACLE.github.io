<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>ML Notes - OnlyourMiracle</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="OnlyourMiracle"><meta name="msapplication-TileImage" content="/download/DragonLogo2.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="OnlyourMiracle"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Learning record"><meta property="og:type" content="blog"><meta property="og:title" content="ML Notes"><meta property="og:url" content="http://example.com/2022/05/31/ML_Notes/"><meta property="og:site_name" content="OnlyourMiracle"><meta property="og:description" content="Learning record"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://example.com/img/ML_Notes1.png"><meta property="og:image" content="http://example.com/img/ML_Notes2.png"><meta property="og:image" content="http://example.com/img/ML_Notes3.png"><meta property="og:image" content="http://example.com/img/ML_Notes4.png"><meta property="og:image" content="http://example.com/img/ML_Notes5.png"><meta property="og:image" content="http://example.com/img/ML_Notes6.png"><meta property="og:image" content="http://example.com/img/ML_Notes7.png"><meta property="og:image" content="http://example.com/img/ML_Notes8.png"><meta property="og:image" content="http://example.com/img/ML_Notes9.png"><meta property="og:image" content="http://example.com/img/ML_Notes10.png"><meta property="og:image" content="http://example.com/img/ML_Notes11.png"><meta property="og:image" content="http://example.com/img/ML_Notes12.png"><meta property="article:published_time" content="2022-05-31T13:33:12.205Z"><meta property="article:modified_time" content="2022-07-26T12:40:17.754Z"><meta property="article:author" content="OnlyourMiracle"><meta property="article:tag" content="Computer science"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/ML_Notes1.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com/2022/05/31/ML_Notes/"},"headline":"ML Notes","image":["http://example.com/img/ML_Notes1.png","http://example.com/img/ML_Notes2.png","http://example.com/img/ML_Notes3.png","http://example.com/img/ML_Notes4.png","http://example.com/img/ML_Notes5.png","http://example.com/img/ML_Notes6.png","http://example.com/img/ML_Notes7.png","http://example.com/img/ML_Notes8.png","http://example.com/img/ML_Notes9.png","http://example.com/img/ML_Notes10.png","http://example.com/img/ML_Notes11.png","http://example.com/img/ML_Notes12.png"],"datePublished":"2022-05-31T13:33:12.205Z","dateModified":"2022-07-26T12:40:17.754Z","author":{"@type":"Person","name":"OnlyourMiracle"},"publisher":{"@type":"Organization","name":"OnlyourMiracle","logo":{"@type":"ImageObject","url":"http://example.com/download/DragonLogo2.png"}},"description":"Learning record"}</script><link rel="canonical" href="http://example.com/2022/05/31/ML_Notes/"><link rel="icon" href="/download/DragonLogo2.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }
          Array
              .from(document.querySelectorAll('.tab-content'))
              .forEach($tab => {
                  $tab.classList.add('is-hidden');
              });
          Array
              .from(document.querySelectorAll('.tabs li'))
              .forEach($tab => {
                  $tab.classList.remove('is-active');
              });
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/download/DragonLogo2.png" alt="OnlyourMiracle" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-05-31T13:33:12.205Z" title="5/31/2022, 9:33:12 PM">2022-05-31</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-26T12:40:17.754Z" title="7/26/2022, 8:40:17 PM">2022-07-26</time></span><span class="level-item"><a class="link-muted" href="/categories/Computer-science/">Computer science</a></span><span class="level-item">19 minutes read (About 2843 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">ML Notes</h1><div class="content"><blockquote>
<p>This article records my process of learning machine learning.</p>
</blockquote>
<span id="more"></span>

<h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><h2 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h2><blockquote>
<p>Reason: 对于大多数数据挖掘算法来说，数据集的标准化是基本要求。这是因为，如果特征不服从或者近似服从标准正态分布（即，零均值、单位标准差的正态分布）的话，算法的表现会大打折扣。实际上，我们经常忽略数据的分布形状，而仅仅做零均值、单位标准差的处理。在一个机器学习算法的目标函数里的很多元素所有特征都近似零均值，方差具有相同的阶。如果某个特征的方差的数量级大于其它的特征，那么，这个特征可能在目标函数中占主导地位，这使得模型不能从其它特征有效地学习。</p>
</blockquote>
<h3 id="Z-score标准化"><a href="#Z-score标准化" class="headerlink" title="Z-score标准化"></a>Z-score标准化</h3><p>这种方法基于原始数据的均值<code>mean</code>和标准差<code>standard deviation</code>进行数据的标准化。将特征<code>A</code>的原始值<code>x</code>使用<code>z-score</code>标准化到<code>x’</code>。<code>z-score</code>标准化方法适用于<strong>特征<code>A</code>的最大值和最小值未知的情况</strong>，或有超出取值范围的离群数据的情况。将数据按其特征(按列进行)减去其均值，然后除以其方差。最后得到的结果是，对每个特征&#x2F;每列来说所有数据都聚集在<code>0</code>附近，方差值为<code>1</code>。数学公式如下：</p>
<img src="/img/ML_Notes1.png" alt="Z-score标准化" class="box px-0 py-0 ml-auto mr-auto" width="360"/>

<p><strong>函数<code>scale</code>为数组形状的数据集的标准化提供了一个快捷实现：</strong>  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">X_train = np.array([[ <span class="number">1.</span>, -<span class="number">1.</span>,  <span class="number">2.</span>],  </span><br><span class="line">                    [ <span class="number">2.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],  </span><br><span class="line">                    [ <span class="number">0.</span>,  <span class="number">1.</span>, -<span class="number">1.</span>]])</span><br><span class="line">X_train = preprocessing.scale(X_train)</span><br></pre></td></tr></table></figure>



<h3 id="Min-Max-标准化"><a href="#Min-Max-标准化" class="headerlink" title="Min-Max 标准化"></a>Min-Max 标准化</h3><p><code>Min-max</code>标准化方法是对原始数据进行线性变换。设<code>minA</code>和<code>maxA</code>分别为特征<code>A</code>的最小值和最大值，将<code>A</code>的一个原始值<code>x</code>通过<code>min-max</code>标准化映射成在区间<code>[0,1]</code>中的值<code>x&#39;</code>，其公式为：  </p>
<img src="/img/ML_Notes2.png" alt="Min-Max 标准化" class="box px-0 py-0 ml-auto mr-auto" width="360"/>

<p><strong>可以使用<code>MinMaxScaler</code>实现，以下是一个将简单的数据矩阵缩放到<code>[0, 1]</code>的例子:</strong> </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"></span><br><span class="line">X_train = np.array([[ <span class="number">1.</span>, -<span class="number">1.</span>,  <span class="number">2.</span>],  </span><br><span class="line">                    [ <span class="number">2.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],  </span><br><span class="line">                    [ <span class="number">0.</span>,  <span class="number">1.</span>, -<span class="number">1.</span>]])</span><br><span class="line">min_max_scaler = preprocessing.MinMaxScaler()</span><br><span class="line">X_train_minmax = min_max_scaler.fit_transform(X_train)</span><br></pre></td></tr></table></figure>

<h3 id="MaxAbs标准化"><a href="#MaxAbs标准化" class="headerlink" title="MaxAbs标准化"></a>MaxAbs标准化</h3><p><code>MaxAbs</code>的工作原理与<code>Min-max</code>非常相似，但是它只通过除以每个特征的最大值将训练数据特征缩放至 <code>[-1, 1]</code> 范围内，这就意味着，训练数据应该是已经零中心化或者是稀疏数据。公式如下：  </p>
<img src="/img/ML_Notes3.png" alt="MaxAbs标准化" class="box px-0 py-0 ml-auto mr-auto" width="360"/>

<p><strong>可以使用<code>MaxAbsScale</code>实现，以下是使用上例中数据运用这个缩放器的例子:</strong>  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"></span><br><span class="line">X_train = np.array([[ <span class="number">1.</span>, -<span class="number">1.</span>,  <span class="number">2.</span>],  </span><br><span class="line">                    [ <span class="number">2.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],  </span><br><span class="line">                    [ <span class="number">0.</span>,  <span class="number">1.</span>, -<span class="number">1.</span>]])</span><br><span class="line">max_abs_scaler = preprocessing.MaxAbsScaler()</span><br><span class="line">X_train_maxabs = max_abs_scaler.fit_transform(X_train)</span><br></pre></td></tr></table></figure>

<h2 id="非线性转换"><a href="#非线性转换" class="headerlink" title="非线性转换"></a>非线性转换</h2><blockquote>
<p>Reason: 对于大多数数据挖掘算法来说，如果特征不服从或者近似服从标准正态分布（即，零均值、单位标准差的正态分布）的话，算法的表现会大打折扣。非线性转换就是将我们的特征映射到均匀分布或者高斯分布(即正态分布)。</p>
</blockquote>
<h3 id="映射到均匀分布"><a href="#映射到均匀分布" class="headerlink" title="映射到均匀分布"></a>映射到均匀分布</h3><p>相比线性缩放，该方法不受异常值影响，它将数据映射到了零到一的均匀分布上，将最大的数映射为<code>1</code>，最小的数映射为<code>0</code>。其它的数按从小到大的顺序均匀分布在<code>0</code>到<code>1</code>之间，如有相同的数则取平均值，如数据为<code>np.array([[1],[2],[3],[4],[5]])</code>则经过转换为：<code>np.array([[0],[0.25],[0.5],[0.75],[1]])</code>，数据为<code>np.array([[1],[2],[9],[10],[2]])</code>则经过转换为：<code>np.array([[0],[0.375],[0.75],[1.0],[0.375]])</code>。第二个例子具体过程如下图：  </p>
<img src="/img/ML_Notes4.png" alt="映射到均匀分布" class="box px-0 py-0 ml-auto mr-auto" width="360"/>

<p>在<code>sklearn</code>中使用<code>QuantileTransformer</code>方法实现，用法如下：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> QuantileTransformer</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">data = np.array([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>],[<span class="number">4</span>],[<span class="number">5</span>]])</span><br><span class="line">quantile_transformer = QuantileTransformer(random_state=<span class="number">666</span>)</span><br><span class="line">data = quantile_transformer.fit_transform(data)</span><br></pre></td></tr></table></figure>



<h3 id="映射到高斯分布"><a href="#映射到高斯分布" class="headerlink" title="映射到高斯分布"></a>映射到高斯分布</h3><p>映射到高斯分布是为了稳定方差，并最小化偏差。在最新版<code>sklearn 0.20.x</code>中<code>PowerTransformer</code>现在有两种映射方法，<code>Yeo-Johnson</code>映射，公式如下：  </p>
<img src="/img/ML_Notes5.png" alt="映射到高斯分布(Yeo-Johnson映射)" class="box px-0 py-0 ml-auto mr-auto" width="360"/>

<p><code>Box-Cox</code>映射，公式如下：</p>
<img src="/img/ML_Notes6.png" alt="映射到高斯分布(Box-Cox映射)" class="box px-0 py-0 ml-auto mr-auto" width="360"/>

<p><strong>在<code>sklearn 0.20.x</code>中使用<code>PowerTransformer</code>方法实现，用法如下：</strong>  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PowerTransformer</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">data = np.array([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>],[<span class="number">4</span>],[<span class="number">5</span>]])  </span><br><span class="line">pt = PowerTransformer(method=<span class="string">&#x27;box-cox&#x27;</span>, standardize=<span class="literal">False</span>)</span><br><span class="line">data = pt.fit_transform(data)</span><br></pre></td></tr></table></figure>



<h2 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h2><blockquote>
<p>Reason: 归一化是缩放<strong>单个样本</strong>以具有<strong>单位范数</strong>的过程。归一化实质是一种线性变换，线性变换有很多良好的性质，这些性质决定了对数据改变后不会造成“失效”，反而能提高数据的表现，这些性质是归一化的前提。归一化能够<strong>加快模型训练速度</strong>，<strong>统一特征量纲</strong>，<strong>避免数值太大</strong>。值得注意的是，归一化是对每一个样本做转换，所以是<strong>对数据的每一行进行变换</strong>。而之前我们讲过的方法是对数据的每一列做变换。</p>
</blockquote>
<h3 id="L1范式归一化"><a href="#L1范式归一化" class="headerlink" title="L1范式归一化"></a>L1范式归一化</h3><p><code>L1</code>范式定义如下：  </p>
<img src="/img/ML_Notes7.png" alt="L1范式归一化" class="box px-0 py-0 ml-auto mr-auto" width="360"/>

<p>表示向量<code>x</code>中每个元素的绝对值之和。<br><code>L1</code>范式归一化就是将样本中每个特征<strong>除以</strong>特征的<code>L1</code>范式。</p>
<p>在<code>sklearn</code>中使用<code>normalize</code>方法实现，用法如下：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> normalize</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = np.array([[-<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],  </span><br><span class="line">                 [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],  </span><br><span class="line">                 [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]])</span><br><span class="line">data = normalize(data, <span class="string">&#x27;l1&#x27;</span>)</span><br></pre></td></tr></table></figure>



<h3 id="L2范式归一化"><a href="#L2范式归一化" class="headerlink" title="L2范式归一化"></a>L2范式归一化</h3><p><code>L2</code>范式定义如下：  </p>
<img src="/img/ML_Notes8.png" alt="L2范式归一化" class="box px-0 py-0 ml-auto mr-auto" width="360"/>

<p>表示向量元素的平方和再开平方根。<br><code>L2</code>范式归一化就是将样本中每个特征<strong>除以</strong>特征的<code>L2</code>范式。</p>
<p>在<code>sklearn</code>中使用<code>normalize</code>方法实现，用法如下：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> normalize</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = np.array([[-<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],  </span><br><span class="line">                 [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],  </span><br><span class="line">                 [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]])</span><br><span class="line">data = normalize(data, <span class="string">&#x27;l2&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>​	</p>
<h2 id="离散值编码"><a href="#离散值编码" class="headerlink" title="离散值编码"></a>离散值编码</h2><h3 id="LabelEncoder"><a href="#LabelEncoder" class="headerlink" title="LabelEncoder"></a>LabelEncoder</h3><p>在数据挖掘中，特征经常不是数值型的而是分类型的。举个例子，一个人可能有<code>[&quot;male&quot;, &quot;female&quot;]</code>，<code>[&quot;from Europe&quot;, &quot;from US&quot;, &quot;from Asia&quot;]</code>，<code>[&quot;uses Firefox&quot;, &quot;uses Chrome&quot;, &quot;uses Safari&quot;, &quot;uses Internet Explorer&quot;]</code>等分类的特征。这些特征能够被有效地编码成整数，比如<code>[&quot;male&quot;, &quot;from US&quot;, &quot;uses Internet Explorer&quot;]</code>可以被表示为<code>[0, 1, 3]</code>，<code>[&quot;female&quot;, &quot;from Asia&quot;, &quot;uses Chrome&quot;]</code>表示为<code>[1, 2, 1]</code>。</p>
<p>在<code>sklearn</code>中，通过<code>LabelEncoder</code>来实现：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line">label = label = [<span class="string">&#x27;male&#x27;</span>,<span class="string">&#x27;female&#x27;</span>]  </span><br><span class="line">int_label = LabelEncoder()</span><br><span class="line">label = int_label.fit_transform(label)</span><br></pre></td></tr></table></figure>



<h3 id="OneHotEncoder"><a href="#OneHotEncoder" class="headerlink" title="OneHotEncoder"></a>OneHotEncoder</h3><p>这种整数特征表示并不能在<code>sklearn</code>的估计器中直接使用，因为这样的连续输入，估计器会认为类别之间是有序的，但实际却是无序的。如将<code>male,female</code>，转换为<code>1,0</code>。<code>1</code>比<code>0</code>要大，机器就会把这个关系考虑进去，而<code>male,female</code>之间是没有这样的关系的。所以我们需要使用另外一种编码方式，<code>OneHot</code>编码。</p>
<p>在<code>sklearn</code>中通过<code>OneHotEncoder</code>来实现，使用方法如下： </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line">label = label = [<span class="string">&#x27;male&#x27;</span>,<span class="string">&#x27;female&#x27;</span>]  </span><br><span class="line">int_label = LabelEncoder()</span><br><span class="line">label = int_label.fit_transform(label)</span><br><span class="line">label = np.array(label).reshape(<span class="built_in">len</span>(label), <span class="number">1</span>)</span><br><span class="line">onehot_label = OneHotEncoder()</span><br><span class="line">label = onehot_label.fit_transform(label).toarray()</span><br></pre></td></tr></table></figure>



<h2 id="生成多项式特征"><a href="#生成多项式特征" class="headerlink" title="生成多项式特征"></a>生成多项式特征</h2><blockquote>
<p>Reason: 在数据挖掘中，获取数据的代价经常是非常高昂的。所以有时就需要人为的制造一些特征，并且有的特征之间是有关联的。生成多项式特征可以轻松的为我们获取更多的数据，并获得特征的更高维度和互相间关系的项且引入了特征之间的非线性关系，可以有效的增加模型的复杂度。</p>
</blockquote>
<h3 id="PolynomialFeatures"><a href="#PolynomialFeatures" class="headerlink" title="PolynomialFeatures"></a>PolynomialFeatures</h3><p>在<code>sklearn</code>中通过<code>PolynomialFeatures</code>方法来生成多项式特征，使用方法如下：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"></span><br><span class="line">data = np.arange(<span class="number">6</span>).reshape(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">poly = PolynomialFeatures(<span class="number">2</span>)</span><br><span class="line">data = poly.fit_transform(data)</span><br></pre></td></tr></table></figure>

<p>特征转换情况如下：  </p>
<img src="/img/ML_Notes9.png" alt="PolynomialFeatures" class="box px-0 py-0 ml-auto mr-auto" width="360"/>

<p>在一些情况下，只需要特征间的交互项，这可以通过设置 <code>interaction_only=True</code>来得到:  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"></span><br><span class="line">data = np.arange(<span class="number">6</span>).reshape(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">poly = PolynomialFeatures(degree=<span class="number">2</span>, interaction_only=<span class="literal">True</span>)</span><br><span class="line">data = poly.fit_transform(data)</span><br></pre></td></tr></table></figure>

<p>特征转换情况如下：  </p>
<img src="/img/ML_Notes10.png" alt="PolynomialFeatures(interaction_only=True)" class="box px-0 py-0 ml-auto mr-auto" width="360"/>



<h2 id="估算缺失值"><a href="#估算缺失值" class="headerlink" title="估算缺失值"></a>估算缺失值</h2><blockquote>
<p>Reason: 由于各种原因，真实世界中的许多数据集都包含缺失数据，这类数据经常被编码成空格、<code>NaNs</code>，或者是其他的占位符。但是这样的数据集并不能被<code>sklearn</code>学习算法兼容，因为大多的学习算法都默认假设数组中的元素都是数值，因而所有的元素都有自己的意义。 使用不完整的数据集的一个基本策略就是舍弃掉整行或整列包含缺失值的数据。但是这样就付出了舍弃可能有价值数据（即使是不完整的 ）的代价。 处理缺失数值的一个更好的策略就是从已有的数据推断出缺失的数值。</p>
</blockquote>
<h3 id="Imputer"><a href="#Imputer" class="headerlink" title="Imputer"></a>Imputer</h3><p><code>sklearn</code>中使用<code>Imputer</code>方法估算缺失值，使用方法如下：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line"></span><br><span class="line">data = [[np.nan, <span class="number">2</span>], [<span class="number">6</span>, np.nan], [<span class="number">7</span>, <span class="number">4</span>],[np.nan,<span class="number">4</span>]]  </span><br><span class="line">imp = SimpleImputer(missing_values=np.nan, strategy=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">data = imp.fit_transform(data)</span><br></pre></td></tr></table></figure>

<p>其中<code>strategy</code>参数用来选择代替缺失值方法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">`mean`表示使用平均值代替缺失值  </span><br><span class="line">`median`表示使用中位数代替缺失值 </span><br><span class="line">`most_frequent`表示使用出现频率最多的值代替缺失值</span><br></pre></td></tr></table></figure>

<p><code>missing_values</code>参数表示何为缺失值：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">`NaN`表示`np.nan`为缺失值  </span><br><span class="line">`0`表示`0`为缺失值</span><br></pre></td></tr></table></figure>



<h1 id="回归算法（此处涉及线性回归）"><a href="#回归算法（此处涉及线性回归）" class="headerlink" title="回归算法（此处涉及线性回归）"></a>回归算法（此处涉及线性回归）</h1><h2 id="线性回归模型"><a href="#线性回归模型" class="headerlink" title="线性回归模型"></a>线性回归模型</h2><h5 id="LinearRegression"><a href="#LinearRegression" class="headerlink" title="LinearRegression"></a>LinearRegression</h5><p><code>LinearRegression</code>的构造函数中有两个常用的参数可以设置：</p>
<ul>
<li><code>fit_intercept</code>：是否有截据，如果没有则直线过原点，默认为<code>Ture</code>。</li>
<li><code>normalize</code>：是否将数据归一化,默认为<code>False</code>。</li>
</ul>
<p><code>LinearRegression</code>类中的<code>fit</code>函数用于训练模型，<code>fit</code>函数有两个向量输入：</p>
<ul>
<li><code>X</code>：大小为**[样本数量,特征数量]**的<code>ndarray</code>，存放训练样本</li>
<li><code>Y</code>：值为整型，大小为**[样本数量]**的<code>ndarray</code>，存放训练样本的标签值</li>
</ul>
<p><code>LinearRegression</code>类中的<code>predict</code>函数用于预测，返回预测值，<code>predict</code>函数有一个向量输入：</p>
<ul>
<li><code>X</code>：大小为**[样本数量,特征数量]**的<code>ndarray</code>，存放预测样本</li>
</ul>
<p><code>LinearRegression</code>的使用代码如下：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(X_train, Y_train)</span><br><span class="line">predict = lr.predict(X_test)</span><br></pre></td></tr></table></figure>



<h2 id="衡量线性回归的性能指标"><a href="#衡量线性回归的性能指标" class="headerlink" title="衡量线性回归的性能指标"></a>衡量线性回归的性能指标</h2><h3 id="R-Squared"><a href="#R-Squared" class="headerlink" title="R-Squared"></a>R-Squared</h3><p>公式如下：</p>
<img src="/img/ML_Notes11.png" alt="R-Squared" class="box px-0 py-0 ml-auto mr-auto" width="360"/>

<p>其中<em>y<strong>m</strong>e<strong>a</strong>n</em>表示所有测试样本标签值的均值。为什么这个指标会有刚刚我们提到的性能呢？我们分析下公式：  </p>
<img src="/img/ML_Notes12.png" alt="R-Squared" class="box px-0 py-0 ml-auto mr-auto" width="360"/>

<p>其实分子表示的是模型预测时产生的误差，分母表示的是对任意样本都预测为所有标签均值时产生的误差，由此可知：</p>
<ol>
<li><em>R</em>2<em>l<strong>e</strong>q</em>1,当我们的模型不犯任何错误时，取最大值<code>1</code>；</li>
<li>当我们的模型性能跟基模型性能相同时，取<code>0</code>；</li>
<li>如果为负数，则说明我们训练出来的模型还不如基准模型，此时，很有可能我们的数据不存在任何线性关系。</li>
</ol>
<p><strong>R2使用代码</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line">r2_score(y_true, y_pred)</span><br></pre></td></tr></table></figure>







</div><div class="article-licensing box"><div class="licensing-title"><p>ML Notes</p><p><a href="http://example.com/2022/05/31/ML_Notes/">http://example.com/2022/05/31/ML_Notes/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>OnlyourMiracle</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2022-05-31</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2022-07-26</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Computer-science/">Computer science</a></div><div class="a2a_kit a2a_kit_size_32 a2a_default_style"><a class="a2a_dd" target="_blank" rel="noopener" href="https://www.addtoany.com/share"></a><a class="a2a_button_facebook"></a><a class="a2a_button_twitter"></a><a class="a2a_button_telegram"></a><a class="a2a_button_whatsapp"></a><a class="a2a_button_reddit"></a></div><script src="https://static.addtoany.com/menu/page.js" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2022/06/04/Reading_Notes_%E3%80%8A%E5%89%91%E6%9D%A5%E3%80%8B/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">《剑来》</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2022/05/30/C%20language%20exercises/"><span class="level-item">C exercises</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/disqusjs@1.3.0/dist/disqusjs.css"><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script src="https://cdn.jsdelivr.net/npm/disqusjs@1.3.0/dist/disqus.js"></script><script>new DisqusJS({
            shortname: 'my-hexo-blog-1',
            apikey: "oWUQ2a5UGyr4N1tQF7JuKw6RZINuwstmRlI2oAxwbmiIcZ0YWPK95jGGu07cQSxs",
            siteName: "OnlyourMiracle",
            identifier: "2022/05/31/ML_Notes/",
            url: "http://example.com/2022/05/31/ML_Notes/",
            title: "ML Notes",
            
            
            
            
        });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/download/DragonLogo.jpeg" alt="OnlyourMiracle"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">OnlyourMiracle</p><p class="is-size-6 is-block">历尽千帆仍少年</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>TsingTao China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">23</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">7</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">8</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ONLYOURMIRACLE" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ONLYOURMIRACLE"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/onlyourmiracle"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/OnlyourMiracle"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com/OnlyourMiracle"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/01/"><span class="level-start"><span class="level-item">January 2025</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">February 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">December 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">June 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/AI/"><span class="level-start"><span class="level-item">AI</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Computer-science/"><span class="level-start"><span class="level-item">Computer science</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Diary/"><span class="level-start"><span class="level-item">Diary</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Knowledge/"><span class="level-start"><span class="level-item">Knowledge</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Life-experience/"><span class="level-start"><span class="level-item">Life experience</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Reading/"><span class="level-start"><span class="level-item">Reading</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Reading-notes/"><span class="level-start"><span class="level-item">Reading notes</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-01-13T02:53:35.534Z">2025-01-13</time></p><p class="title"><a href="/2025/01/13/25%E8%80%83%E7%A0%94%E5%A4%8D%E8%AF%95&amp;&amp;%E8%BD%AF%E8%80%83%E7%BD%91%E5%B7%A5%E6%9C%AC%E7%BA%AA/">25考研复试&amp;&amp;软考网工本纪</a></p><p class="categories"><a href="/categories/Diary/">Diary</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-03-29T11:05:18.688Z">2024-03-29</time></p><p class="title"><a href="/2024/03/29/AI%20Project/">AI Project</a></p><p class="categories"><a href="/categories/AI/">AI</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-03-24T07:34:49.183Z">2024-03-24</time></p><p class="title"><a href="/2024/03/24/Pytorch%20Learning%20Tour/">Pytorch Learning Tour</a></p><p class="categories"><a href="/categories/AI/">AI</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-03-20T13:48:47.057Z">2024-03-20</time></p><p class="title"><a href="/2024/03/20/ChatBot%20Training%20Tour/">ChatBot Training Tour</a></p><p class="categories"><a href="/categories/AI/">AI</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-03-13T13:29:55.798Z">2024-03-13</time></p><p class="title"><a href="/2024/03/13/AI%20Chat%20Bot/">AI Chat Bot</a></p><p class="categories"><a href="/categories/AI/">AI</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-science/"><span class="tag">Computer science</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Exam/"><span class="tag">Exam</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Kaoyan/"><span class="tag">Kaoyan</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Knowledge/"><span class="tag">Knowledge</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Life-experience/"><span class="tag">Life experience</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reading/"><span class="tag">Reading</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reading-notes/"><span class="tag">Reading notes</span><span class="tag">9</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/download/DragonLogo2.png" alt="OnlyourMiracle" height="28"></a><p class="is-size-7"><span>&copy; 2025 OnlyourMiracle</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ONLYOURMIRACLE"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>